{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D to 3D LSTM\n",
    "\n",
    "This is the first approach to try to estimate 3D points coordinates from 2D keypoints extracted with Openpose. Here I will build a simple LSTM to perform the task over the Panoptic Studio dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import all the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch utilities\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "# Plotting utilities\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# Directory and file utilities\n",
    "from os import listdir\n",
    "from os.path import isfile, isdir, join\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data acquisition\n",
    "Now I will define some functions in order to parse and organise the data, and later convert it to pytorch tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is structured as follows: in the dataset directory there are several folders, each folder corresponds to a recording; each of these folders contains a folder with the audio, folders with face, hands and body keypoints estimations for each frame, and a folder with the video recorded from different views.\n",
    "\n",
    "In this first approach I will be using the keypoints estimations. Every keypoint folder (face, hands or body) is organized the same way: it contains a json per frame of the video, which includes the 3D keypoints estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `get_keypoints` will go through each folder in the dataset directory and retrieve the face keypoints, the hands keypoints and the body keypoints. It will separate them into input (2D coordinates per joint per frame) and grountruth (third coordinate to estimate for each input 2D keypoint). \n",
    "The input will be of shape $([n videos, seq len, input size])$, where *seq_len* = number of frames, and *input_size* = face + hands + body keypoints, that is (70+(21+21)+26)x2 -multiplied by 2 because there are x and y coordinates-. The groundtruth (label) data will be of the same shape, except that the last dimension size will not be multiplied by 2 (there's only one coordinate to estimate).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keypoints(data_path):\n",
    "    dataset = []\n",
    "    groundtruth = []\n",
    "    # Look over just the folders inside the directory\n",
    "    for p in list(map(lambda x: join(data_path, x), filter(lambda x: isdir(join(data_path, x)), listdir(data_path)))): \n",
    "        # Gets 2 list of n_frames lists, one for the 2D coordinates and one for the third coordinate.\n",
    "        # Each list of the n_frames lists contains, either the (x and y) or the z of each keypoint for the face(first line), hands(second), body(third).\n",
    "        # e.g. the first line will result in [[x1,y1,x2,y2...x70,y70]sub1...[x1,y1...x70,y70]subN], [[z1,z2...z70]sub1...[z1..z70]subN]\n",
    "        # Actually, as there will be two of each list above because there are two people en each video.\n",
    "        face_2d, face_3d = get_face(p)\n",
    "        hands_2d, hands_3d = get_hands(p)\n",
    "        pose_2d, pose_3d = get_body(p)\n",
    "        \n",
    "        # Concatenates the coordinates for the face, hands and body on the last dimension, for each person.\n",
    "        vid_input_p1, vid_input_p2 = ([fa+ha+po for fa, ha, po in zip(face_2d[i], hands_2d[i], pose_2d[i])] for i in range(2))\n",
    "        vid_labels_p1, vid_labels_p2 = ([fa+ha+po for fa, ha, po in zip(face_3d[i], hands_3d[i], pose_3d[i])] for i in range(2))\n",
    "        \n",
    "        dataset.append(vid_input_p1)\n",
    "        dataset.append(vid_input_p2)\n",
    "        groundtruth.append(vid_labels_p1)\n",
    "        groundtruth.append(vid_labels_p2)\n",
    "        print(f'Completed folder {p}')\n",
    "    return dataset, groundtruth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions are in charge of retrieving the keypoints from each json. The json face json has a key *people* with a list of person objects. Each person object has *id* field and *landmarks* field, the latter containing a list of 3D coordinates for each keypoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_face(path):\n",
    "    face_2D_seq = ([], [])\n",
    "    face_3D_seq = ([], [])\n",
    "    # List only the files (json), for there might be folders containing invalid frames.\n",
    "    files = list(filter(lambda x: isfile(x), map(lambda x: join(path, 'hdFace3d', x), sorted(listdir(join(path, 'hdFace3d'))))))\n",
    "    for f in files[1:]: # The first frame of face keypoints estimation it's blank\n",
    "        with open(f, 'r') as j:\n",
    "            json_array = json.load(j)\n",
    "            i = 0\n",
    "            for person in json_array['people']:\n",
    "                if person['id'] != -1: # If the id is -1, it means there's no person\n",
    "                    two_coord = []\n",
    "                    third_coord = []\n",
    "                    for c in range(len(person['face70']['landmarks'])):\n",
    "                        # Put the x, y coordinates from z.\n",
    "                        if (c+1)%3==0:\n",
    "                            third_coord.append(person['face70']['landmarks'][c])\n",
    "                        else:\n",
    "                            two_coord.append(person['face70']['landmarks'][c])\n",
    "                    face_2D_seq[i].append(two_coord)\n",
    "                    face_3D_seq[i].append(third_coord)\n",
    "                    i+=1\n",
    "            if i<2: # In case there was only one person detected on a frame\n",
    "                face_2D_seq[i].append([0. for i in range(140)])\n",
    "                face_3D_seq[i].append([0. for i in range(70)])\n",
    "    print('Face completed.')\n",
    "    # Each return var being a tuple with the list of n_frames list of coordinates for each person\n",
    "    return face_2D_seq, face_3D_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hands json contains the *landmarks* field inside both *left_hand* and *right_hand* field. As there are some frames that may not have one of the hands estimated, I've had to put some exception handling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hands(path):\n",
    "    hand_2D_seq = ([], [])\n",
    "    hand_3D_seq = ([], [])\n",
    "    files = list(filter(lambda x: isfile(x), map(lambda x: join(path, 'hdHand3d', x), sorted(listdir(join(path, 'hdHand3d'))))))\n",
    "    for f in files[1:-1]: # The first and the last frames of these folders are blank.\n",
    "        with open(f, 'r') as j:\n",
    "            json_array = json.load(j)\n",
    "            i = 0\n",
    "            for person in json_array['people']:\n",
    "                if person['id'] != -1:\n",
    "                    try:\n",
    "                        # Separate x,y from z\n",
    "                        hands = [[person[hand]['landmarks'][c] for c in range(len(person[hand]['landmarks'])) if (c+1)%3!=0] for hand in ['left_hand', 'right_hand']]\n",
    "                        hand_2D_seq[i].append(hands[0]+hands[1])\n",
    "                        hands_3d = [[person[hand]['landmarks'][c] for c in range(len(person[hand]['landmarks'])) if (c+1)%3==0] for hand in ['left_hand', 'right_hand']]\n",
    "                        hand_3D_seq[i].append(hands_3d[0]+hands_3d[1])\n",
    "                    except Exception as e: # In case left_hand or right_hand keys don't exist.\n",
    "                        if 'left_hand' in str(e): \n",
    "                            try: # Just put a 0., 0., 0. estimation for each keypoint of the left_hand\n",
    "                                hands = [0. for i in range(42)]+[person['right_hand']['landmarks'][c] for c in range(len(person['right_hand']['landmarks'])) if (c+1)%3!=0]\n",
    "                                hands_3d = [0. for i in range(21)]+[person['right_hand']['landmarks'][c] for c in range(len(person['right_hand']['landmarks'])) if (c+1)%3==0]\n",
    "                            except: # In case neither left_hand nor right_hand exist\n",
    "                                hands = [0. for i in range(84)]\n",
    "                                hands_3d = [0. for i in range(42)]\n",
    "                        elif 'right_hand' in str(e): # Just put a 0., 0., 0. estimation for each keypoint of the right_hand\n",
    "                            hands = [person['left_hand']['landmarks'][c] for c in range(len(person['left_hand']['landmarks'])) if (c+1)%3!=0]+[0. for i in range(42)]\n",
    "                            hands_3d = [person['left_hand']['landmarks'][c] for c in range(len(person['left_hand']['landmarks'])) if (c+1)%3==0]+[0. for i in range(21)]\n",
    "\n",
    "                        hand_2D_seq[i].append(hands)\n",
    "                        hand_3D_seq[i].append(hands_3d)\n",
    "                    i+=1\n",
    "            if i<2:\n",
    "                hand_2D_seq[i].append([0. for i in range(84)])\n",
    "                hand_3D_seq[i].append([0. for i in range(42)])\n",
    "    print('Hands completed.')\n",
    "    return hand_2D_seq, hand_3D_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The body json is organised a bit differently, inside each person object contains the *joints26* field with a list of 3D coordinates. But this list is structured as follows: *[x1,y1,z1,acc1,x2,y2,z2,acc2...]*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_body(path):\n",
    "    body_2D_seq = ([], [])\n",
    "    body_3D_seq = ([], [])\n",
    "    files = list(filter(lambda x: isfile(x), map(lambda x: join(path, 'hdPose3d_stage1_op25', x), sorted(listdir(join(path, 'hdPose3d_stage1_op25'))))))\n",
    "    for f in files[:-1]:\n",
    "        with open(f, 'r') as j:\n",
    "            json_array = json.load(j)\n",
    "            i = 0\n",
    "            for person in json_array['bodies']:\n",
    "                if person['id'] != -1:\n",
    "                    two_coord = []\n",
    "                    third_coord = []\n",
    "                    for c in range(len(person['joints26'])):\n",
    "                        if (c+1)%4!=0: # Discard the accuracy value\n",
    "                            if (c+1)%4==3: # Separate z from x,y\n",
    "                                third_coord.append(person['joints26'][c])\n",
    "                            else:\n",
    "                                two_coord.append(person['joints26'][c])\n",
    "                    body_2D_seq[i].append(two_coord)\n",
    "                    body_3D_seq[i].append(third_coord)\n",
    "                    i += 1\n",
    "            if i<2:\n",
    "                body_2D_seq[i].append([0. for i in range(52)])\n",
    "                body_3D_seq[i].append([0. for i in range(26)])\n",
    "    print('Body completed.')\n",
    "    return body_2D_seq, body_3D_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face completed.\n",
      "Hands completed.\n",
      "Body completed.\n",
      "Completed folder ../../../data/DB keypoints/190419_asl2\n",
      "Face completed.\n",
      "Hands completed.\n",
      "Body completed.\n",
      "Completed folder ../../../data/DB keypoints/190419_asl4\n",
      "Face completed.\n",
      "Hands completed.\n",
      "Body completed.\n",
      "Completed folder ../../../data/DB keypoints/190419_asl5\n",
      "Face completed.\n",
      "Hands completed.\n",
      "Body completed.\n",
      "Completed folder ../../../data/DB keypoints/190425_asl1\n",
      "Face completed.\n",
      "Hands completed.\n",
      "Body completed.\n",
      "Completed folder ../../../data/DB keypoints/190425_asl2\n",
      "Face completed.\n",
      "Hands completed.\n",
      "Body completed.\n",
      "Completed folder ../../../data/DB keypoints/190425_asl3\n"
     ]
    }
   ],
   "source": [
    "data_path = '../../../data/DB keypoints'\n",
    "dataset, groundtruth = get_keypoints(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset structuring\n",
    "Now let's convert the lists obtained to Pytorch tensors and organise them in train, validation and test datasets. \n",
    "First, I will define a padding function in order to make all the sequences of video frames the same length, so I can train the LSTM in batches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8751"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def padding_seq(dataset):\n",
    "    max_seq = max([len(x) for x in dataset])\n",
    "    for seq in dataset:\n",
    "        for i in range(max_seq-len(seq)):\n",
    "            seq.append([0. for j in range(len(seq[0]))])\n",
    "    return max_seq\n",
    "\n",
    "max_seq = padding_seq(dataset)\n",
    "padding_seq(groundtruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 8751, 276]) torch.Size([12, 8751, 138])\n"
     ]
    }
   ],
   "source": [
    "# From python lists to pytorch tensors.\n",
    "dataset = torch.tensor(dataset)\n",
    "groundtruth = torch.tensor(groundtruth)\n",
    "print(dataset.shape, groundtruth.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each axis I normalize the values between -1 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_1(tensor, coordinates=1):\n",
    "    max_value = [tensor[:, :,i::coordinates].max().item() for i in range(coordinates)]\n",
    "    min_value = [tensor[:, :,i::coordinates].min().item() for i in range(coordinates)]\n",
    "    center = [(max_value[i]+min_value[i])/2 for i in range(coordinates)]\n",
    "    for j in range(coordinates):\n",
    "        subtensor = tensor[:, :, j::coordinates]\n",
    "        subtensor.sub_(center[j])\n",
    "        subtensor[subtensor > 0] = subtensor[subtensor > 0].div(max_value[j]-center[j])\n",
    "        subtensor[subtensor < 0] = subtensor[subtensor < 0].div(abs(min_value[j]-center[j]))\n",
    "\n",
    "    return [max_value[i]- center[i] for i in range(coordinates)]\n",
    "\n",
    "_ = normalize_1(dataset, 2)\n",
    "scale = normalize_1(groundtruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 8751, 276]) torch.Size([2, 8751, 276]) torch.Size([2, 8751, 276])\n",
      "torch.Size([8, 8751, 138]) torch.Size([2, 8751, 138]) torch.Size([2, 8751, 138])\n"
     ]
    }
   ],
   "source": [
    "l1, l2 = len(dataset), len(groundtruth)\n",
    "# Split in train, validation and test\n",
    "training_kp, val_kp, test_kp = dataset[:round(0.67*l1)], dataset[round(0.67*l1):round(0.85*l1)], dataset[round(0.85*l1):]\n",
    "training_lbl, val_lbl, test_lbl = groundtruth[:round(0.67*l2)], groundtruth[round(0.67*l2):round(0.85*l2)], groundtruth[round(0.85*l2):]\n",
    "print(training_kp.shape, val_kp.shape, test_kp.shape)\n",
    "print(training_lbl.shape, val_lbl.shape, test_lbl.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we define the batch_size and put the datasets in DataLoaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7e7173dc10>\n"
     ]
    }
   ],
   "source": [
    "train_data = TensorDataset(training_kp, training_lbl)\n",
    "val_data = TensorDataset(val_kp, val_lbl)\n",
    "test_data = TensorDataset(test_kp, test_lbl)\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have a GPU available we set our device to GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print some examples to see whether it is loaded correctly or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8751, 276]) torch.Size([2, 8751, 138])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print(sample_x.shape, sample_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building\n",
    "It is time to build the model for this approach. It will consist on a single/double layer LSTM followed by a Linear layer with output size the number of keypoints we want to estimate. I also define a method to initialize the hidden_state of the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_2D3D(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super().__init__()\n",
    "        # Save the model parameters\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Define the architecture\n",
    "        self.lstm = nn.LSTM(input_size, hidden_dim, n_layers, batch_first=True)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, output_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, state):\n",
    "        # Describe the forward step\n",
    "        batch_size, seq_len = x.size(0), x.size(1) # We save the batch size and the sequence length\n",
    "        ht, hidden_state = self.lstm(x, state)\n",
    "        ht = ht.contiguous().view(-1, self.hidden_dim) # Need to flatten and reshape the output to feed it to the Linear layer\n",
    "        ot = self.fc(ht)\n",
    "        ot = ot.view(batch_size, seq_len, -1) # Reshape the output for it to be torch.Size([batch_size, seq_len, output_size])\n",
    "        return ot, hidden_state\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_2D3D(\n",
      "  (lstm): LSTM(276, 512, batch_first=True)\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=138, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define some model parameters\n",
    "INPUT_SIZE = sample_x.size(2)\n",
    "OUTPUT_SIZE = sample_y.size(2)\n",
    "HIDDEN_DIM = 512\n",
    "N_LAYERS = 1\n",
    "\n",
    "# Instantiate the model\n",
    "model = LSTM_2D3D(INPUT_SIZE, OUTPUT_SIZE, HIDDEN_DIM, N_LAYERS)\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Now we will proceed with the training. The first cell will define the learning rate, the loss function and the selected optimizer for the training process. Then we will proceed with a training over a number of epochs in which we will print it's training loss and validation loss. I also will be using Tensorboard to have a much nicer view of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 7e-4\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "writer = SummaryWriter(log_dir=f'/deeplearning/logs/test{datetime.now()}_lr-{lr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 1/25 in 3.70s.\n",
      " Loss: 0.1748  Val Loss: 0.10620534420013428\n",
      "Finished epoch 2/25 in 3.25s.\n",
      " Loss: 0.1408  Val Loss: 0.084391750395298\n",
      "Finished epoch 3/25 in 3.26s.\n",
      " Loss: 0.1138  Val Loss: 0.0850166380405426\n",
      "Finished epoch 4/25 in 3.26s.\n",
      " Loss: 0.1106  Val Loss: 0.08267021179199219\n",
      "Finished epoch 5/25 in 3.27s.\n",
      " Loss: 0.1021  Val Loss: 0.07081208378076553\n",
      "Finished epoch 6/25 in 3.27s.\n",
      " Loss: 0.0921  Val Loss: 0.06172812730073929\n",
      "Finished epoch 7/25 in 3.28s.\n",
      " Loss: 0.0839  Val Loss: 0.053990643471479416\n",
      "Finished epoch 8/25 in 3.26s.\n",
      " Loss: 0.1456  Val Loss: 0.057127345353364944\n",
      "Finished epoch 9/25 in 3.27s.\n",
      " Loss: 0.0859  Val Loss: 0.06885078549385071\n",
      "Finished epoch 10/25 in 3.26s.\n",
      " Loss: 0.0839  Val Loss: 0.055982474237680435\n",
      "Finished epoch 11/25 in 3.27s.\n",
      " Loss: 0.0786  Val Loss: 0.045032307505607605\n",
      "Finished epoch 12/25 in 3.28s.\n",
      " Loss: 0.0745  Val Loss: 0.04304412007331848\n",
      "Finished epoch 13/25 in 3.28s.\n",
      " Loss: 0.0728  Val Loss: 0.04469643533229828\n",
      "Finished epoch 14/25 in 3.26s.\n",
      " Loss: 0.0716  Val Loss: 0.049306806176900864\n",
      "Finished epoch 15/25 in 3.28s.\n",
      " Loss: 0.0717  Val Loss: 0.049290988594293594\n",
      "Finished epoch 16/25 in 3.27s.\n",
      " Loss: 0.0710  Val Loss: 0.04641997441649437\n",
      "Finished epoch 17/25 in 3.27s.\n",
      " Loss: 0.0693  Val Loss: 0.044672541320323944\n",
      "Finished epoch 18/25 in 3.26s.\n",
      " Loss: 0.0695  Val Loss: 0.04401187226176262\n",
      "Finished epoch 19/25 in 3.26s.\n",
      " Loss: 0.0697  Val Loss: 0.04372873902320862\n",
      "Finished epoch 20/25 in 3.27s.\n",
      " Loss: 0.0690  Val Loss: 0.04365299269556999\n",
      "Finished epoch 21/25 in 3.27s.\n",
      " Loss: 0.0673  Val Loss: 0.04266774654388428\n",
      "Finished epoch 22/25 in 3.26s.\n",
      " Loss: 0.0669  Val Loss: 0.04239020124077797\n",
      "Finished epoch 23/25 in 3.28s.\n",
      " Loss: 0.0669  Val Loss: 0.04201240837574005\n",
      "Finished epoch 24/25 in 3.26s.\n",
      " Loss: 0.0667  Val Loss: 0.042389944195747375\n",
      "Finished epoch 25/25 in 3.27s.\n",
      " Loss: 0.0655  Val Loss: 0.04081541672348976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7e72b0cf50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOydd5ycZbn3v/f03Z3tNVuSTYVUkhASEKQJGEQpCgJHVGzYOKC+niPn2FHO66seRI8oNqwgB0EkIBBaEAktCQkhvSdbsr3Olqn3+8dT9pm6s5vMZDbc389nPzvztLlndue+nuv6Xdd1CyklCoVCoVDEYjvRA1AoFApFbqIMhEKhUCgSogyEQqFQKBKiDIRCoVAoEqIMhEKhUCgS4jjRAzheVFRUyMbGxhM9DIVCoZhSbNq0qUtKWZlo30ljIBobG9m4ceOJHoZCoVBMKYQQh5PtUyEmhUKhUCREGQiFQqFQJEQZCIVCoVAk5KTRIBQKxclFMBikubmZ0dHREz2UkwKPx0N9fT1OpzPtc5SBUCgUOUlzczOFhYU0NjYihDjRw5nSSCnp7u6mubmZmTNnpn2eCjEpFIqcZHR0lPLycmUcjgNCCMrLyyfsjSkDoVAochZlHI4fk/kslYFQZJUtTX1sa+k/0cNQKBRpoAyEIqt89/EdfH/t7hM9DIViXPr6+vjZz3424fPe85730NfXl4ERZR9lIBRZxR+KEAiFT/QwFIpxSWYgQqFQyvOeeOIJSkpKMjWsrKKymBRZJRiOEI6o+xJF7nPbbbexf/9+li5ditPpxOPxUFpayq5du9izZw9XXnklTU1NjI6Ocuutt3LTTTcBY21/fD4fl156Keeccw4vv/wydXV1PProo+Tl5Z3gd5Y+ykAosko4IgmG1TK3ionx7ce2s6N14Lhec0FtEd9838Kk+7/3ve+xbds2tmzZwgsvvMBll13Gtm3bzDTRe++9l7KyMkZGRjjjjDP4wAc+QHl5edQ19u7dy5///Gd+9atf8cEPfpCHH36YG2644bi+j0yiDIQiq4QiknBEGQjF1GPlypVRNQQ/+clPeOSRRwBoampi7969cQZi5syZLF26FIDTTz+dQ4cOZW28x4OMGgghxGrgx4Ad+LWU8nsx+z8DfB4IAz7gJinlDiFEI7ATMNTMV6WUn8nkWBXZIRSJEFIGQjFBUt3pZ4uCggLz8QsvvMCzzz7LK6+8Qn5+Pueff37CGgO3220+ttvtjIyMZGWsx4uMGQghhB24G7gYaAY2CCHWSCl3WA67X0p5j3785cCdwGp9334p5dJMjU9xYgiFJeFI5EQPQ6EYl8LCQgYHBxPu6+/vp7S0lPz8fHbt2sWrr76a5dFlh0x6ECuBfVLKAwBCiAeAKwDTQEgprUHFAkDdWp7khCKSkNIgFFOA8vJyzj77bBYtWkReXh7V1dXmvtWrV3PPPfcwf/58TjnlFM4888wTONLMkUkDUQc0WZ43A6tiDxJCfB74EuACLrTsmimE2AwMAF+TUv4zwbk3ATcBTJ8+/fiNXJExQmEVYlJMHe6///6E291uN08++WTCfYbOUFFRwbZt28ztX/7yl4/7+DLNCc83lFLeLaWcDXwF+Jq++SgwXUq5DM143C+EKEpw7i+llCuklCsqKxOumKfIMZRIrVBMHTJpIFqABsvzen1bMh4ArgSQUvqllN36403AfmBehsapyCKhsCSkNAiFYkqQSQOxAZgrhJgphHAB1wFrrAcIIeZanl4G7NW3V+oiN0KIWcBc4EAGx6rIEmHlQSgUU4aMaRBSypAQ4mZgLVqa671Syu1CiNuBjVLKNcDNQoiLgCDQC3xUP/1c4HYhRBCIAJ+RUvZkaqyK7BGKRFShnEIxRchoHYSU8gngiZht37A8vjXJeQ8DD2dybIrsE4lIIhLlQSgUU4QTLlIr3j4Y2UtKg1AopgbKQCiyhmEYlAehOBnxer0AtLa2cvXVVyc85vzzz2fjxo0pr3PXXXcxPDxsPj+R7cOVgVBkDcODCIYlUiojoTg5qa2t5aGHHpr0+bEG4kS2D1cGQpE1rBXUyolQ5Dq33XYbd999t/n8W9/6Ft/97nd517vexfLly1m8eDGPPvpo3HmHDh1i0aJFAIyMjHDdddcxf/58rrrqqqheTJ/97GdZsWIFCxcu5Jvf/CagNQBsbW3lggsu4IILLgC09uFdXV0A3HnnnSxatIhFixZx1113ma83f/58PvWpT7Fw4UIuueSS49bzSXVzVWQNq/YQikSw2+wncDSKKcWTt0HbW8f3mjWL4dLvJd197bXX8oUvfIHPf/7zADz44IOsXbuWW265haKiIrq6ujjzzDO5/PLLk673/POf/5z8/Hx27tzJ1q1bWb58ubnvjjvuoKysjHA4zLve9S62bt3KLbfcwp133sm6deuoqKiIutamTZv47W9/y2uvvYaUklWrVnHeeedRWlqasbbiyoNQZA2rB6F0CEWus2zZMjo6OmhtbeXNN9+ktLSUmpoa/vM//5MlS5Zw0UUX0dLSQnt7e9JrvPjii+ZEvWTJEpYsWWLue/DBB1m+fDnLli1j+/bt7NixI9llAHjppZe46qqrKCgowOv18v73v59//lPrQJSptuLKg1BkDatRULUQigmR4k4/k1xzzTU89NBDtLW1ce2113LffffR2dnJpk2bcDqdNDY2JmzzPR4HDx7khz/8IRs2bKC0tJQbb7xxUtcxyFRbceVBKLJGMDwWYlIehGIqcO211/LAAw/w0EMPcc0119Df309VVRVOp5N169Zx+PDhlOefe+65ZsO/bdu2sXXrVgAGBgYoKCiguLiY9vb2qMZ/ydqMv/Od7+Rvf/sbw8PDDA0N8cgjj/DOd77zOL7beJQHocgaVqOgaiEUU4GFCxcyODhIXV0d06ZN40Mf+hDve9/7WLx4MStWrODUU09Nef5nP/tZPvaxjzF//nzmz5/P6aefDsBpp53GsmXLOPXUU2loaODss882z7nppptYvXo1tbW1rFu3zty+fPlybrzxRlauXAnAJz/5SZYtW5bRVerEyZJuuGLFCjlefrHixLKjdYD3/ESLmb7yHxcyrXjqLN6uyD47d+5k/vz5J3oYJxWJPlMhxCYp5YpEx6sQkyJrRHkQSoNQKHIeZSAUWSM6zVUZCIUi11EGQpE1rEZBrUutSIeTJQSeC0zms1QGQpE1rGEl5UEoxsPj8dDd3a2MxHFASkl3dzcej2dC56ksJkXWiAoxKQ1CMQ719fU0NzfT2dl5oodyUuDxeKivr5/QOcpAKLJGKKI8CEX6OJ1OZs6ceaKH8bZGhZgUWSO61YbSIBSKXEcZCEXWCKsQk0IxpVAGQpE1gkqkViimFMpAKLJGWGkQCsWUQhkIRdaIbtanNAiFItfJqIEQQqwWQuwWQuwTQtyWYP9nhBBvCSG2CCFeEkIssOz7D/283UKId2dynIrsoFptKBRTi4wZCCGEHbgbuBRYAFxvNQA690spF0splwLfB+7Uz10AXAcsBFYDP9Ovp5jCBFWISaGYUmTSg1gJ7JNSHpBSBoAHgCusB0gpByxPCwBj1rgCeEBK6ZdSHgT26ddTTGHCYdWLSaGYSmSyUK4OaLI8bwZWxR4khPg88CXABVxoOffVmHPrEpx7E3ATwPTp04/LoBWZQ/ViUiimFidcpJZS3i2lnA18BfjaBM/9pZRyhZRyRWVlZWYGqDhuhJQGoVBMKTJpIFqABsvzen1bMh4ArpzkuYopgEpzVSimFpk0EBuAuUKImUIIF5rovMZ6gBBiruXpZcBe/fEa4DohhFsIMROYC7yewbEqskBQaRAKxZQiYxqElDIkhLgZWAvYgXullNuFELcDG6WUa4CbhRAXAUGgF/iofu52IcSDwA4gBHxeShnO1FgV2cHqQVgFa4VCkZtktJurlPIJ4ImYbd+wPL41xbl3AHdkbnSKbKNabSgUU4sTLlIr3j6E1ZKjCsWUQhkIRdYIhiVuh/YvF1YGQqHIeZSBUGSNcETicWoF8SrNVaHIfZSBUGSNUCSCy2FDCFUop1BMBZSBUGSNUFjitAkcNhHVl0mhUOQmykAoskY4IrHbBXabUBqEQjEFUAZCkTWCEYnTZsNhsykNQqGYAigDocga4UgEu03gsAulQSgUUwBlIBRZIxiWOOw2pUEoFFMEZSAUWSMckThsugahQkwKRc6jDIQiawTDERx2oWkQyoNQKHIeZSAUWcPwIJQGoVBMDZSBUGSNUFhi10NMSoNQKHIfZSAUWSMUieDURWqlQSgUuY8yEIqsEYoYHoTSIBSKqYAyEIqsEQpLHDYbTqVBKBRTAmUgFFkjFImYaa7Kg1Aoch9lIBRZIxSRepqrUK02FIopgDIQiqwRVSinPAiFIudRBkKRNUJ6qw2n3UZIaRAKRc6TUQMhhFgthNgthNgnhLgtwf4vCSF2CCG2CiGeE0LMsOwLCyG26D9rMjlORXZQGoRCMbVwZOrCQgg7cDdwMdAMbBBCrJFS7rActhlYIaUcFkJ8Fvg+cK2+b0RKuTRT41NkH82DUBqEQjFVyKQHsRLYJ6U8IKUMAA8AV1gPkFKuk1IO609fBeozOJ5j4rUD3XQMjJ7oYUxpQhEtzVVpEArF1CCTBqIOaLI8b9a3JeMTwJOW5x4hxEYhxKtCiCsTnSCEuEk/ZmNnZ+exjzgFn/zDRn7z0sGMvsbJTihsrAehNAiFYiqQsRDTRBBC3ACsAM6zbJ4hpWwRQswCnhdCvCWl3G89T0r5S+CXACtWrMjoLemQP0TfcDCTL3HSE5XmqjwIhSLnyaQH0QI0WJ7X69uiEEJcBHwVuFxK6Te2Sylb9N8HgBeAZRkca0pC4QgRCT5/6EQN4aQgZElzVRqEQpH7ZNJAbADmCiFmCiFcwHVAVDaSEGIZ8As049Bh2V4qhHDrjyuAswGruJ1V/CEtHKIMxOSRUup1EHqzPuVBKBQ5T8ZCTFLKkBDiZmAtYAfulVJuF0LcDmyUUq4BfgB4gb8IIQCOSCkvB+YDvxBCRNCM2Pdisp+ySkA3EEPKQEwaI6TkMDUIZSAUilwnoxqElPIJ4ImYbd+wPL4oyXkvA4szObaJoDyIY8fwGIw1qZVIrVDkPqqSOg0CykAcM8Gw9hmqNakViqmDMhBp4A+FARViOhbGPAiVxaRQTBXe9gai2+dn9V0vsubN1qTHqBDTsROrQSiRWqHIfd72BsLlsLGrbZD2/uRV0oaBCIal6U0oJoaR1mpoEEGlQSgUOc/b3kAUuDSdfjCFd2BoEABDfmUgJoMhStt1DUJKiCgvQqHIad72BsJmExS47PhGkxsIq9eQ6jhFcgwPwqlrEIDSIRSKHOdtbyAAvB5HSgHa6kEoHWJyGMbAbrPhsGv/dkqHUChym7QMhBBitqWy+XwhxC1CiJLMDi17FLgdKSf+QNgSYgooAzEZjBCTwzbmQSgdQqHIbdL1IB4GwkKIOWjN8RqA+zM2qixTOI6B8ActHoQKMU0KU6TWNQhA1UIoFDlOugYiIqUMAVcB/yOl/DdgWuaGlV28nvQ9CBVimhyhmDoI6zaFQpGbpGsggkKI64GPAo/r25yZGVL2KXA5UovUwTGRWhXLTY6wGWJSGoRCMVVI10B8DDgLuENKeVAIMRP4Y+aGlV2UB5F5gglCTMGw0iAUilwmrWZ9eifVW0BrxQ0USin/XyYHlk0mpEEoAzEpYpv1WbcpFIrcJN0spheEEEVCiDLgDeBXQog7Mzu07GFkMUmZeMIKhCMIAXlOuwoxTRLDW7BbPAilQSgUuU26IaZiKeUA8H7gD1LKVUDCVt1TEa/HQTgizZYasfhDEdwOmx6KUpXUk8HwFpx2gVNpEArFlCBdA+EQQkwDPsiYSH3S4HXr7TaSCNWBUASX3YZ3nFCUIjljhXJKg1AopgrpGojb0VaG2y+l3CCEmAXszdywsothIJKFj/yhMG6nnQK3CjFNlrFWG0qDUCimCumK1H8B/mJ5fgD4QKYGlW0MA5HMO/ArD+KYiW3Wp21TBkKhyGXSFanrhRCPCCE69J+HhRD1mR5cthgvxOQPRXA7dQOhKqknhbWSWmkQCsXUIN0Q02+BNUCt/vOYvu2kwOtJHWIyNIgCt0P1Ypok1jRX04NQGoRCkdOkayAqpZS/lVKG9J/fAZUZHFdWGS/EFAhFcDvteN2pu74qkhNM0KxPhZgUitwmXQPRLYS4QQhh139uALrHO0kIsVoIsVsIsU8IcVuC/V8SQuwQQmwVQjwnhJhh2fdRIcRe/eej6b+liWOGmFKJ1LoGkSwMpUhNOJKgWZ8yEApFTpOugfg4WoprG3AUuBq4MdUJQgg7cDdwKbAAuF4IsSDmsM3ACinlEuAh4Pv6uWXAN4FVwErgm3oFd0ZIJ8TkdmohJn8ookIjk2Cs1YbN1CCUB6FQ5DZpGQgp5WEp5eVSykopZZWU8krg1nFOWwnsk1IekFIGgAeAK2Kuu05KOaw/fRUwhO93A89IKXuklL3AM8DqNN/ThMlz2rGJ5K28rVlMoJYdnQxmsz67UBqEQjFFOJYV5T44zv46oMnyvFnfloxPAE9O5FwhxE1CiI1CiI2dnZ3jjzgJQoiUiwYFLFlMAIP+4KRf6+2K4UHYlQahUEwZjsVAiOM1CF3TWAH8YCLnSSl/KaVcIaVcUVl5bJp5qoZ9fksWEygPYjKMtdqwKQ1CoZgipCyU07WAhLsY30C0oK08Z1Cvb4t9jYuArwLnSSn9lnPPjzn3hXFe75jwepLXOARCEVx6LyZQHV0ngxFOsgmUBqFQTBHGq6TeBEgSG4Px4iwbgLn62hEtwHXAv1gPEEIsA34BrJZSdlh2rQX+yyJMXwL8xzivd0ykqnHwh8K4HXa8bjugDMRkCEUkTrtACKVBKBRThZQGQko5c7IXllKGhBA3o032duBeKeV2IcTtwEYp5Rq0kJIX+IsQAuCILob3CCG+g2ZkAG6XUvZMdizpkCqF1fAgCsbp2aRITjgiTcOgNAiFYmowXojpBinln/THZ0sp11v23Syl/Gmq86WUTwBPxGz7huVx0pbhUsp7gXtTD//44XU7ONo/mnCf0e67wKVCTJMlGJY4bVpoSWkQCsXUYDyR+kuWx/8Ts+/jx3ksJ5RkVdLhiCQUkbgcNgoNDUIVy02YcCSC3a57EEqDUCimBOMZCJHkcaLnU5pkInVAX0TI7bCrENMxEIxIM7TkUBqEQjElGM9AyCSPEz2f0njdDnyB+GVHDQPhcmgVwC6HDZ9q2DdhwmGJIybEpDwIhSK3GS+L6VQhxFY0b2G2/hj9+ayMjizLeN0OpIThQNj0FAD8Ya3mwe3QJrdC1fJ7UgQjkTiRWmkQCkVuM56BmJ+VUeQA1hqHKAMRHPMgQE+HVSGmCRPW01xBeRAKxVRhvDTXw9bnQohy4Fy0dNRNmRxYtrG2/K62bA+EDQ1izED4VCX1hAmFx9JchdDabRj9mRQKRW6SUoMQQjwuhFikP54GbEPLXvqjEOILWRhf1jANREz4yPAgokJMqhfThAlFImYFNWhehLHKnEKhyE3GE6lnSim36Y8/htZh9X1obbhPujRXiK9xGPMgtCrqArdd9WKaBFYPAjQdQoWYFIrcZjwDYb1Vfhd60ZuUchA4qeIDBUkMhD+oGQOlQRwboYg06x9A8yCUSK1Q5DbjidRNQoh/RWu3vRx4CkAIkQc4Mzy2rJKsCM7wIAwDUehxJF15TpGcsKUOArSGfSGlQSgUOc14HsQngIVoq8ddK6Xs07efCfw2g+PKOmYRXCC1BlHgUh7EZAiGI1EGQmkQCkXuM14WUwfwmQTb1wHrMjWoE4G5GNA4HkSB28FwIEwkIrHZTqpi8owSjkjczrH7EaVBKBS5z3jN+tak2i+lvPz4DufE4XbYcNpFvAYRMgrlNJHaCEUNBUIUek6qKFtGCUYk+TaLBmFXGoRCkeuMp0Gchbb055+B1zjJ+i9ZMZYdjQ0fWVttQLSYrQxE+oQjEZxWDcJmUx6EQpHjjGcgaoCLgevRFvv5O/BnKeX2TA/sROBN0EbDH4ovlAPVsG+ixKa5ahqEEqkVilwmpUgtpQxLKZ+SUn4UTZjeB7ygLwR00uF1x2coxXoQY6vKxddCPL+rndcOdGd4lFMTbUW5mEI55UEoFDnNeB4EQgg3cBmaF9EI/AR4JLPDOjEkWhMi1oPwurWwUqKGfd/9+056hgI8/3/Op6zAleHRTi1C4Uh0oZzSIBSKnGe8Vht/AF5Bq4H4tpTyDCnld6SULVkZXZbxehwJRGrdg7AbIabk61L3DgXoGw7yf5/YmeGRTj20QjlrJbXSIBSKXGe8OogbgLnArcDLQogB/WdQCDGQ+eFlF6873kAY61Hra2ab6bCxnkY4IukfCVLkcfCXTc28fjCjS2hPOULh6EI5h9IgFIqcZzwNwialLNR/iiw/hVLKomwNMlskFqnDuC2x82Q9mwZGgkQkfPq82dSV5PG1v71l6heKxK02lAehUOQ243kQbyuSeRDWAq9kPZt6hwMA1JXk8e3LF7Kn3cdv1x/M8IinDqFIdCW10iAUitwnowZCCLFaCLFbCLFPCHFbgv3nCiHeEEKEhBBXx+wLCyG26D8pC/aOF16PViVtnbj8oYipP4AmVjtsIi7E1Dus9TUsyXdy0YJqTmso4bmdHdkY9pTAuuQoKA1CoZgKjJvFNFmEEHbgbrQ6imZggxBijZRyh+WwI2h9nr6c4BIjUsqlmRpfIryWfkxFehGcoUEYCCHwehxxLTl6hzQPojRfy16qL81jZ2u8TBMMR4hIaVZmv12IF6mVBqFQ5DqZ9CBWAvuklAeklAHgAeAK6wFSykNSyq3kSOvwRIsG+UPhuMm8NN9Fjx5SMjBCTIaBqPS66Rz0x73G1/+2jU/8buNxHfdUIDbEpNp9KxS5TyYNRB1amw6DZn1buniEEBuFEK8KIa5MdIAQ4ib9mI2dnZ3HMlYgcZV0rAcBUOF10RUz+ffpIabSAs3zqCx0M+gPMRqMLqjb1TbIttb+Yx7rVCMU0+7bYVcitUKR6+SySD1DSrkCrcXHXUKI2bEHSCl/KaVcIaVcUVlZecwv6NUb8Vmrqf2hiFkkZ1DhddPlizYQvcMBHDZheiEVXs2TiD2uc9BP33CQwdG3z7Kl4YhESrDHaBDKg1AocptMGogWoMHyvF7flhZGMZ6U8gDwArDseA4uEYUJQkyJPQg3Xb74EFNJvsusl6jwugGijpNS0jE4CkBL38jxfwM5irEwUKwGEVQahEKR02TSQGwA5gohZgohXMB1QFrZSEKIUr3FB0KICuBsYEfqs46dRCGmZB5E/0gwqs6hdyhIab4z6hggSofoHQ4S1BfJae55GxkI/T0rDUKhmFpkzEBIKUPAzcBaYCfwoJRyuxDidiHE5QBCiDOEEM3ANcAvhBBGl9j5wEYhxJtoCxN9Lyb7KSOYiwaNp0EUauGj7iHr5B+g1NJ/qbLQ8CDGjjG8B3i7eRC6gbCkCysNQqHIfTKW5gogpXwCeCJm2zcsjzeghZ5iz3sZWJzJsSXCXAzInzqLyQwfDQaYVpwHaCJ1Y0W+eUy5oUFYPIiOgbHHzb3Dx3n0uYuRzhrdakNpEApFrpPLInXWMTwIIyMJkmsQEO0d9AwHzBRX0FagK/I4YjwI7bHHaaO59+3jQYRNDyI6xKQ0CIUit1EGwoLDbqM4z0mfpcYhEI7XICoNfUGf/KWU9OkitZWKQrd5DIyFmJbUl0zKQOxqG+B7T+6a9J13orqMbBCMxGsQDqVBKBQ5jzIQMZQVuOixeBD+YHINwvAOhgJhgmFJWUH0EqSVXjddg2PGpmPAT6HbwZwq76RCTI+92co9/9jPo1sm3m19e2s/Z9zxLDsSVHdnmrApUkevSa00CIUit1EGIobSfKfZNgPAH47EaRD5Lgf5Lrs5+RvHJ/IgrCGmzkE/lUVu6kvz6B0OTnjZUuP1/vvpPfhD8SvapeJQl2aQjvQMTei840EwQZqrU2kQCkXOowxEDGUFLnr0CV9KmVCDgOhiudg2Gwax7TY6BkepKnRTX6qJ2RPNZOr0+cl32WnpG+FPrx6Z0Lk9Q8ZYs1+gZ2oQtuh231oBnTISCkWuogxEDKX5LnPCD4Sjlxu1UuF1WQyE3mYj3xl3jLXdRsegn6pCD/WlWubTRMNMnYN+zmgs45w5Ffz0+b0MTKAau2coqI81MM6Rxx+jDsIeo0EAKsykUOQwykDEUFbgonsogJQybj1qK1YPwhC1S2PWobbWQkgpaR8wPAjDQEzQgxj0U1no5iurT6V3OMivXjyQ9rmmBzF0AgxEJD7N1a6Hm1SYSaHIXZSBiKGswEUgFGE4EDYrpROGmArH2m3Etvo2j7G029A8iQhVRW4qCty4HBNLdY1EJN1DmoFYXF/Me5dM49f/PJi2F2EI7ycixBRKkObq1MNNyoNQKHIXZSBiMLyAnqHAuB5E73CAUDhCz3AQIaA4LzbENNZuwyiSqyr0YLMJ6kvyJhRi6h/R2nQYKbYfO7uRkWCYdbvSW5TI8CD6TmCIKVaD0PapWgiFIldRBiKGMt0L6B0OpPQgKr0upNQMSd9wgOI8Z1SMHTQvA7QQk1EDUaVvqyvNm5AHYdRTGNdc1lBKhdfN0zva0zp/TIM4ER5EgmZ9dqVBKBS5jjIQMUR7EJq4nGj1twpLsVzvcDAuvKQdM9Zuw8hmqirSzqsvzZ+QgTBadhgehM0muHhBNS/s6ohbcyIRY1lMJ9KDiK6kBqVBKBS5jDIQMZQVJPAg7Ik1CND0Ba2K2hl3jLXdhhFiqiz0ANqSpD1DAYYD6dVCGB6EIXwDXLKwmqFAmFf2d6c8V0pJr+5B9J3INFfL56g0CIUi91EGIgYjxNQzFBzTIJyJNQjQ7ux7hgIJPQgYa7fRMTiKx2mjSG8IaGQytaTpRRgeiNVAvGN2OV63g6d3tKU81+cPEQhH8Dht9A0HiGR5Ug4maNanNAiFIvdRBiKGQo8Du03QO5Tag7CmsPYlCTGBng47GDBrIIwFhSaa6to56MdlHzMwoHko559SyTM72lOGagzvYWaFl4iEwbuGrasAACAASURBVNGJVXAfK4ma9R1PDWL9vi4+eu/rKlylUBxnlIGIwWYTlOY76bGEmNzOeA2iwGXH47TR5fNra0EkCDGBZkiMEFOV5e7fqKZON5Op06eluBoGxuCShTV0+QJsPtKb9Fxj3YrZlQWA1nk2myRq1nc8NYhX9nfzjz2dJ6wZoUJxsqIMRAJK8130WkTqRB6EEIIKr5uWvhGGA+G4IjkDo91Gx+CoKVAb21329GshOgf9pu5h5fxTKnHaRcpsJkOYnl3pjXqeLcJmoVz0mtQwJmAfC8b7aRsYHedIhUIxEZSBSIBRTZ1KgwAtfLSvwweQUKTWjtHabbT0jVClC9SgeSoTSXXtHPSbGUxWijxO3jG7grXb25L2NerWC/pm6R5EtmshgilbbRy7BtE3ooXQ2pWBUCiOK8pAJKCswPAgkmsQoBmIg11ad9SyFBoEwGgwEiUwg6ZDpBti6vL5qSxM/BoXL6jmcPewaaxiifMghsYymUaDYb704BaOdGduhTsjjOS0fI7246hB9A8rA6FQZAJlIBJQWuCKSnON8yCGuiEcorLQZd4dx7b6NrAahaoYA7Gkvpi3WvrHnZzDEUnPUCChBwFamAngH3s6E+7vGQristto0HUPa4jprZZ+/vpGC/e8uD/lGI4Fwwgk8iAmokE09Qzz/K74UFrfiB5i6o82EK8f7OGCH74woaaGbze2t/Zz8Z3/oNun9BtFPMpAJKAs30XvcNAsQHPbLSK1fxB+cxE8dgsVlgWCSguShZgsBqLIE7Xvw2c2YrcJfvNS6qZ73UN+IpI4D8SgvjSfOVXeFAbCT2mBk0KPA5uIroUw0mwf3dyCb4LrU6RLsjWptX3pGQgpJbc8sJnP37c5LpRmvJ9YDeK1A90c7Bo6IYskTRXW7+tib4ePjYeTJzko3r5k1EAIIVYLIXYLIfYJIW5LsP9cIcQbQoiQEOLqmH0fFULs1X8+mslxxlJa4CIckWYzvqhWG+5CWHItbLmPS1t+AmiTVao6CINYD6Km2MPlp9Xx4MbmlF1WE9VAxHLevEpeO9jDSCC+qrpnSEvDtdkEJZZ25jC2JsVQIMyaLa1Jr38spE5zTU+DeHZnB5uP9DESDDMc8x77koSYDH0nWehNAfs7tBCpMqKKRGTMQAgh7MDdwKXAAuB6IcSCmMOOADcC98ecWwZ8E1gFrAS+KYQozdRYYzGWDm3r1yaYuF5M530Fzvw8C47czxcdDwHJRepyS3ZTrIEAuOncWYwEw/zp1cNJx2MYqookISbQDEQgFOHVg/FV1T1Dfsr1th+l+c4oD6K5d4SyAhen1hRy32uHM7KATzBVs740QkzhiOSHa3ebz3ssxjQYjpieT2yIqUnXd5SBSM6BLu2z2XFUGQhFPJn0IFYC+6SUB6SUAeAB4ArrAVLKQ1LKrUDsbeS7gWeklD1Syl7gGWB1BscaheENtA2M4rCJuCZ8CAHvvoOOOR/kVscjfM71RMJ+TQAep51CjwOHTST0Mk6pKeT8Uyr5/SuHkvZUSseDWDmzDI/Txj92x4eZrL2iSmM8iNa+EepK8vjQqulsbx1ga3N/0teYLOFEzfoMDSKNENOaN1vY3T7IVcvqgGgD0a9nMLkcNtoHouPohgexv1MZiGTs71QehCI5mTQQdUCT5Xmzvu24nSuEuEkIsVEIsbGzM3H8fTIY/Zja+kcTtvrWX5zBi3/I4+FV/LvtT7Dp90mvV1noprLQjS3W0OjcdO4sunwBfvPSQf76RjP//tCb3P7YDnO/YSBSeRAep50zZ5XzYgIdotvnNz2ZknxX1ATbohuIK5bVkee0c/9rE1vK1Mqn/7iRz923iaaeaNE9mKBZnyPNXkyBUIQ7n9nDwtoibjhzBhBtIAxvaG6VF58/ZHoT4YiktU+FmFLROxSgZyhAVaFWz3MiWsErcpspLVJLKX8ppVwhpVxRWVl53K5r9SAStfo2qCjK54vBz7PReTo8ditsezjhcbXFedSW5CW9zlmzyllcV8wP1u7mSw++ySObW7h3/UFzgusc9FPgslPgdiS9BmhhpgNdQ1FZUcFwhIHRkFnIZw0xSSlp6R2htiSPIo+TK5bWsubNVnYeHaBjYDShngGwr2Mwrslgz1CAtdvbeeKtNi668x/c9ewe0yMKRyR2m4iqAo/VIEaD4YSNC/+yqYmmnhH+7d2nmN1xu6M8CO3xKTWFwFiYqW1glFBE0lCWx9H+0ZQCfDrdcI8FKXNz7W0jvHTZkmlAel6ElJIHNzTx6JYWtjT1mSnGJ5JwRGb8b5gOyb4vyRgOhHK+PUwmDUQL0GB5Xq9vy/S5x4wRrx8NRpKGjgCKPA6E3cXPq74J08+Cv94Ee56OO+67Vy7i+1cvSXodIQT//cHTuP2KhTxxyztZc/M5AKY30OVLXEUdy7nz9HTXvWNehBFOMjwII4VX2xdkJBimTu8L9aFVMxgJhrn0x/9k5X89x4JvPsXa7dGNAP2hMO/7n/X85Ll9Udu3NGlZMHddu5SLF1Rz17N7+a8ndgIQjETiwnSxrTa+/rdtfPx3G+Le0+sHe6gryeO8eZWmZ2e0LocxD+JU3UAYQrXhxZw/rwqA/Um8iHW7O1j0zbXsaks/xHK0f2RCX+zLf7qeHz+3N+3js4UhUL93SS2Qng6xvXWAf394K7c+sIUr717P0u88zQu7Uy9a9aNn9rClqe/YB5yEO/6+k8t/+tIxN6Fct7uDFd99dlJGr61/lNO+/TTPprE+SyQi+dWLB1j67Wf4/cuHJjHS7JFJA7EBmCuEmCmEcAHXAWvSPHctcIkQolQXpy/Rt2WFPKfdDC2l8iCEENQUeyguLoZ/eQCqF8KDH4ZDL0Ud11hRYBapJWNedSEfOauRBbVFnFpTSE2Rhxf1iT5ZFXUssyoKqC/Ni9IhjKK4UjPE5MQfijASCJsprnW6d7O4vpiHPnMWP75uKd+9chFuh43XD/ZEvcbh7mFGgmHW7+uK2r75SB82obUg/+m/LOe8eZXmueGwxBljIMxKaj38tOPoAPv0CctKx4CfacVak0Ov24HLbovyIIwFkE6pKQLGPAhDf7jgVM1oJgozjQbDfOPRbYQiMu0YfO9QgPN+8AIPbWqK2/d/n9jJpph00WA4wvbWfra1HH9t51jZ3+XDZbdxWn0xNUUetqfxGRif468+soJ7bjgdKUl53mgwzI+f28tv1x88buOO5a2WPva0+9hwqGf8g1Nw36uH6fL52dMxOOFz97QPEghH+Ovm5pTHtfSN8C+/fpU7nthJIBxhb46HPzNmIKSUIeBmtIl9J/CglHK7EOJ2IcTlAEKIM4QQzcA1wC+EENv1c3uA76AZmQ3A7fq2rCCEMO9Wk2oQOj+/YTlfvuQU8BTDDY9AyQy4/zpoeeOYXv/ceRX8c28XoXDEbNSXznnnzavk5f1dZpGf0aivrGBMpAbNs2jp0+6yjc6yACsay7hiaR03nDmDWRXeOIH3gP58e2t/VAHa5iN9nFpTRL5LC4MtrC1iX4cPfyhMSA8xWTHWhjDuxFv6Ruge8se1/+70+c0eVsbfpTdKg9AeGx5Em8WDEALOnFWO0y7Yl0Covucf+2nq0QxJum3Xd7UNEghFeDNGzO/2+fnFiwd4dEu0o9s+MEpEwtH+9Ku8/3fDEX79z/jamKe2tfGrF1PXzEyE/R1DNFbk47DbWFBblJaRPNA1hE3AufMqWL2ohkKPI2UFe5degLfhYPpf358+v3dCd9aH9ZDqX9+YfJChbzhg1hFNZClgAyNjbt2uzqShplA4wvt/tp63mvv5/geWMK/aG+UNj8dIIJz1UFpGNQgp5RNSynlSytlSyjv0bd+QUq7RH2+QUtZLKQuklOVSyoWWc++VUs7Rf36byXEmwphIU3kQAAtri8f0hYJy+MjfIL8U/vQB6Ng16dc/b14Vg6Mh3mzu0zyINAwEwDvnVjIcCJsuveFBlFk0CNAMRHOMBxHLnCpv3J23kfUSkbDpkHa3HI5ItjT1sWx6iXncgtoiQhHJ3nYfoUgkqs0GjHkQwUiEIX+IvuGguYSrlVjvqbTAFZfFZBNa88PiPKc5WTX3jlBd6CHf5aCxvCDufRzpHuZnL+znvUumUeF1p90Ta69+dxl7vT3tPvN1rbT2aeOZSBuQ+19v4vtP7Y6qbg6FI3z7se38+Lm9x03PONDlY1aF5tkurC1iX6dv3AnoQKeP+tJ8M/RaU+RJ+d6MBIvW/lGz5iYVgVCEu9ft5/bHd6RlsEYCYToG/Thsgr+/dXTCOoDBk9vazGQK46ZhIhh/95Fg2PT8Y+kY9NM+4Oe298zng2c0UBbzvzweH733df7toa0THtuxMKVF6kySrgcRR1EtfORRsLvgD1dAz+Rc63PmVGAT8MyODvpHgikzmKysmlkGaFXEMBavj/Ug+oaDtPaNku+yJ63hmF3ppaVvJOpLt7/DR4XXhdMuzJqL/Z0+fP4Qy6aPlaosmKaFfHYcHSAUjvcgrBqEdeLosLTs9ofC9I8Eo4xjud5I0aBvOEhxnhObTVBT5LGEmIZpKNMM35wqb5wG8e3HtuOwCb522QLqS/PSmrxACyVAvIHYpxuOWE/ESDTo8o11Bx6PzoFRAuEID24cC1c8u7PdFNtj03knQzAc4Uj3MLOrtAaOC6YVEY5I8/0l40DnkNn0EbRiz7YU4zFqeCA9L2LzkV5GgmGklPzHX7eOq/UYd/tXn16Pzx8ad/GsZDy6pYVZFQVUFrrjsvDSoblXywYsyXfy1LbEYzAMaV2J1lGhvMAd9b+cisHRIBsP9/DC7o6sCtvKQCTBiNmP50EkpGyW5kmE/ZqRGDg64UsU5zs5raGEv23W3OZ0PYhSvejtNf3L2GNoEPljIjWMhZhqS/Li1pgwmFPlRcqxbBfQjMH8aUWcVl/Cqwe019hyRPNWrB7EjPIC8l12drQOEIrIqBRXiNYgrJOqdU0HY3KxvvfYu66+kaDZB6uqyB3lQRhrbsyp8nK4Z9gMu720t4vndnXwhYvmUlPsoW5CBkL7LHqGAlF3+Mb2lr6RqDv8KOOXxsQeiUjTSN732mFzMvjDK4dNo3o80naP9AwTikjTg1hQqxn0VHpCJCI52DVkngNQXeShPUX4zAgx2W0iLY1g/b4ubAJuv2IRbzb384dXDqU83ggvXbOigbqSPB6eRJiprX+U1w72cPnSWhom0GHZSlPPMI0V+Vw8v5pnd7ab/2tWDMNudHWeiAex+UifudjX9tbs6VnKQCShTL+rTpXFlJKq+XDDwzDcDX+8EvqawNep/e7eD+3boWUTHH4Z9j8Pu5+E7Y/Am/+r1VRs/hMfrjxAweB+8hhNS6Q2OHNWOZsO9xIMR+gZ8lPocZghHsNb6B0KmDUQyTDuLo2wkpSS/Z1DzK70smpWGdta+vH5Q2xu6qU4z8nM8rE7S7tNcGpNITuODhCOyKj1qCFag2iO8iDGJptEBYJlBS56fNEaRHGe9p5qijy0DYwSDEc42j9Cg66tzK70Eo5IDnVr7+Pe9Qep8Lr56DsaAU2DaekdGTcLRkrJ3vZB8zOzTtRG6MnnD5nFezDmQUB661X0DgcIRSQrG8to7h3hH3s62NcxyMv7u/mwXgeybxIiaiyGRzW7SpvsG0rzKXQ7UoZ12gZGGQmGmWnxIKqLtCV1k93VGn/DVTPL0jMQ+7tZUl/Ch1ZN5/xTKvnB2t0pjfcR/W6/sTyfq5bV8dLezgl39X18aytSwuWn1dJQlm/qCROhuXeEhtJ8Ll1cw+BoiPX7u+KOMcZVrfdkK/e66BsOprXs7sZDPRj3WOOtQX88SZ1Y/zbmmDwIg7rT4foH4L6r4a5FEz79/cD79bkx9GgJ/KMBiuuhuA6K6qC4YexxUS3YtYly1cwyfvfyIbY299MzHIxq91GSZ3gQQVp6R1hSXxL7siaN5QXYxNhE2DHox+cPMauygMbyAu5et59Nh3vZfKSPpQ0lcYWAC2qLeHRzK5WF7qQeRDASobs3gMMmCEVk1F12h/6FqvSONTksL9DW1/CHwrgddvqGg2Zack2xh85BP829I0QkUR4EaO/DabfxvO49GMa/viSPQDhCl88f11DRSvdQgN7hIB9YXs+vXzrIvk4fq2aVA7C33WfeETb3jphezdF+bS3y0WAkrhVIIgzv4UNnTudQ9xB/eOUwjeUFuOw2br5wDn99ozmh4D5RDKNvhItsNsH8aUUpU12N1vazKywhpiIP4YikO8ln1+XzU+RxcPacCn6wdje9Q4Gki2sNjgbZ0tTHZ86bhRCC71yxiEt+9CL/vXY3d167NOE5R3qGKXDZKStwcdXyOn66bh9/29zCp8+bnd4HAax5s5XFdcXMqvTSUJrP41uPEgpH4m5qkjEaDNPl81NfmsfZcyoodDt46q02LjilKuq4dr0zg/F9NH73DAei1opJxMbDvSyoLWI4EObVA90Ten/HgjIQSSg7HgYCYOY74WNPwuH14PBYflz6b3f0b7u+PRwg3N/C136/ltJgO59b4sE70gb9TXDkFRiNySt3eeGcL8JZN7PS0CEOdsd9IV0OG163g9a+EXqHgyk9CI/TTkNZvpnJZN51VnpZ2lCCwyZ4fmc7u9sHWb2oJu78BdOK+dOrRzjcPRTVZgMsGkRY0yBqS/LoHwnSaQnbGI+jPAjvmIZSXWSnbyRgLqVaXeQhIjGXXzWys4xJcF+Hj9cP9uC0C/5l1XTzmkYdSFPvSEoDYcTnz51XyZ9fP8JePazU7fPTPRTgqmV1PLK5hebeERbVFQOaB7GkvoTXD/akdWc7FqfO4/qV0/nJ83t53dnDexbXUOF1J0wcmAwHOn1UFrop8ozpTwtqi3hwY5NZ2JjoHIBZldEhJtC8i2QGorLQzYoZmj616XAvFy2oTjim1w/2EI5Izp5TAUBDWT5nz6lIabSO9AwzvbwAIQSzK70sm17CIwkMxLaWfp7e0c6XLp4Xtf1g1xBbm/v52mXzAe1/JhyRHO0fpaEsP+nrWjF0EEO8v3B+FU/vaOOO8KIoI9M2MEqVpaNCWYH2f61Vsyf/vwuGI2w+0se1ZzQQDEd4dEvrhAzYsaAMRBImLVInom659jNB7GUzGZiXz5+3HuXWy1eDNdzl98FAC/Q3az97n4bnvwNv/J7yS+5gbmURrx3ooXsoYIpiBiX5TjPWbE1xTcScyjGB1zAUsyu9FLgdLK4v5sGNzUhJlEBtYMS1d7cNMqeqMGrf2IpykpbeYepK8nA7bFEehBGeMDwEGFuYqdsXoLrIQ9/wmAZRo09QRutq4wue73JQV5LHm019vHawh/cuqY36QhqeRkvfCKfPSN4T0jAIp9QUMrtqLAXYyGU//5RKHtncEhUSaekbYeXMMt5q7k8r1dXwIKqLPFy/cjo/XbeP4UCYD5/VCGje0PO7jr2tzP5On2lYDYw71MPdQ1FGYOycIfJddqotS+eaBqJ/lCX18a/TOeinwuvmtIYSXHYbGw71JDUQL+3rwu2wsdzyvzSt2MPGw8lDU0d6hqPexzlzKrh73T4CoUjUzd1fNjbx+1cOc90ZDVFdDZ7RRW2jmtz4n2nqHU7bQDTpmoWRFLF6YQ2Pbmnl9UM9vGN2hXlcx4Cf6uKx/zuz8NOXWofY0TrASDDMGY1lSCT3vXaEt1r6E37njjdKg0iCMREdFwNxDHzu/Nl89T3z47UQtxcqT4E574LTPwrX3QcfWaN5Eg9+mF/IbzNwaDOdg/64JoGl+S52t2l3w6k8CNBi1Ae6hghHNP2hwDJBrJpZzoieFrk0QajqlOpCbELrxeSM8SCE0JogGllMdaV5VBa6oz2IQT9lBa6oFNmxauoAoXCEwdGQqavU6F8+I15bY/kyzqny8tyuDnz+EDfq2oOB8RmMVwuxp32QIo+DqkLtTt4wGHt1z2LlzDIKXHbzjnJgNMjgaIi6kjw92ycNA2GE1Qrd1BR7uHJpHWc0lrJcTwCYU+Wly+c/phYXhpYUawSMifZwkiyeA11DzKwoiEpqMD7j9sHEAnyXL0BFoRuP086S+mJeT6FDrN/XpTedHPtfrynWbgISpa9GIlLzICwT+fSyfCKSON3ikC5mbz4S7XlvPNRLY3k+04q1/wFjUa3mCaS6NveMeRAAZ8/VjEJs48u2gVGqLTcm5QlaxyTCuOFZ0VjKmXpI85UD2dEhlIFIQqnpQUxSpD5OLKwt5lPnzkrv4Fnnwaf/CZf9N/X+/TwkvsKtoz+nzh39hS/JdxLQhbG6cTyI2ZUFBEIRWnpHtLvOKq85QayapYWyZlUWUJwgVTbPZWemHq9OFLKw2wTDeh57XUkeVYXuOJE6tkX62JfKb4rBJbpIbdzN7mn3Ma04L8qwGDrE8uklnNYQbcwK3A5K851xBVKx9QZ7233Mqy5ECMGcKi9tA6MMjAbZ2+Gj0O2gpkjPiNINzVG9BqK2JC8qBTcVHYNazN6YJH94zRL+96azzM/c1FM6Jy9U9wwF6B8JxlX3G3fWrUlE4YNdvjijUuF1Y7eJpJlMXZY6lhWNWmJDosm+Y3CUPe2+qDtuGPMKExnXjkE/gVCE6ZbkiEb9/81ISDA4rD83wo+g/X3fONIX7bGUeLAJJiRUN/eO4HLYzPdZ5HFSVuAyM6wM2gdGo25arDc7qdh4qIeGsjyqizxUeN3MrfKaGYSZRhmIJBw3DSLb2B1wxifp/9Rr/CF8Cdfbn+ezW6+BV++BcHTRnMMmxhXHrBPSAT2DyWDFjFLsNsGyhuSu7oJaLRbvtMV/jg6boKl3GCkZ8yAG/ebEnKiC3Bq37TMMRP6Y6Gd4KrGhs7n6+7jx7JkJxxmb6nq0f4TF33qadXqfISklezoGmVtdqF9P+72/w8ee9kHmVGuGs65k7DrGRFtreBDpGIgBv2noQPO0rOL/nErtdY9FhzhgiM0xIaaqQg92m0hoIEaDYZp7R5hVEX2O3Sao9LoTTuCjwTCD/pD5N1w5s5RgWCbsy/TyPu2O+Jw50QZimj6hHu2PH5ORwWT1IGaUa49jG1YaqaubLa/d1DNCl8/PcktY0Wm3Ma14Yqmuzb0j1JfkRf2dppflc6RnzEgNB0IMjobMrgCgefJCkHK5VyklGw71smJGmbntrNnlbDzUQzCN7KdjZYrNftnDCFt4ppqB0KmsmsYfSz7HpYHv0VuyCJ76Cvz8bNj3nBlyqin2JLyzt2IYhLeaB2jpG4maVAo9Tn5xw+l84aK5Sc83CuaSeRDGF7m+JI+qQg+jwQiDeufVRD2oivOc2ISWpms06jO8F5vF4MXGj997Wi13XLWI9yQQ00ELM1knhX/u7cLnD/HzF7S1urt82usZhsYwnHs7fOzr8DFPNxj1pfnmdQxDYYSY2gdGo1Jp32zqi5vo2wdHoyaRuHGWalrNsRgIoy+U8R4M7HqxoeH5WDncrRnyWTFGBbRU10QC/Fibeu3/7fTpZQih3RHHsn5fF8V5TlO3MjDuuBMZV8MrsBqISq+bfJc9yoNo7RshFJFUeF281dJv1ihsOqKNI1Z3qi/Nm1CxXFPvcJwnPqM8n0NdY9cwaiCsISa7vkZMqhDTkZ5hunx+VjSOjfGsWeUMB8Jsbc5cA0SDqTn7ZQG3w86Pr1vKNSsaxj84R1k1q4y9sp7tF/4OrvszhAPwp/fz4UNfoVEcHVd/AO3uvMLr4pmdmpgXG2K4aEF1SjHP+MLHZjGBdrdm3AUaHgRgehEdCVqM2PVlU7uHAmarbyPEBJj6SKwH4XU7+NCqGUkzP+pL82npHStyM6p+Xz/Yw/bWflNnmKd7EA2lebgcNjYc7KHLF2Butdd8H/0jQQZHgxztH8FhE5qeUOQhFJFRk8HNf36Dbz+2PWocHQP+qEkkFrtNMKvy2DKZntnRzuzKAjNmbqW2xJOw7sDMYKqIF6+rk7Tb6IrJQivOdzK9LJ/dCaq1Nxzq4cxZZXE3EjWmBxF//aaeYWwiWkcTQjC9LD8qvGPoD+9dUksgFDGzot443IfX7TD/pgYTrYWwFmUazCjL52j/iGmMjM/HGmKC8YvlNujtbM5oHPMgjNTqbNRDKAORgiuW1qWdyZCLnKXHc6uL8+DU98DnX4OLb6eh/w2edv07/2f4Lmh7a9zrzKr0sq1F+1KN15U2FsODiK2DAG2yGwmGEQKmFeeZekPHgJ+B0RCBUCRhBbnxpTI8CKsIb3wBGxJMfqmoK8ljJBg2u8NuONTDqpll5Dnt/Hb9ITPFdZ5uCBx2G7MqCnhab+9shJ4Mw9TSN0Jr3yjVRZqXFnsn3O3z09QzEjXRSyk1rymFBwF6j6xJ1kL0DgV47WBPwrRk0P4OrQnCOUZYamYCDyJZ+CzRUrkzKwrMegqD0WCYIz3DZkdeK/kuR1SPLStHeoaZVpwXFwZuLC8wvQsY8zTev1xbc8zQITYd7mVpQ0mcUaovzaN9wJ9Wa5Qhf4ieoYCZwWQwo7yAiBxLgR0rkosNmab2IDYe6qHI42CO5XtnLBGcDaFaGYiTmPcunsZ9n1zFQsNtd7jh7Ft5/uInuD/8LpYNvgD3nAO/fx/sWQuRxDFNIxRhE2Mx3nQxVtNLdOduGI2qQrcm8hkehM+fcpnVaXkRLmz7DUtf+yKniCNRvaSM+P146buxGMc39w7TMTDKoe5hLppfzQdOr2PNllZePdBDcZ4zajxzqrymUG4YDmtGlLVSPVZsNTJcrIsZ9Q0HCYQjKT0I0FKPm3vHemTt6/Dxx1cPMzg6fmbTszvbCUck716Y2EDUluTR1j8aV1V+oHOI6iI33gSLVlUXeRgYDcWJz4lWQjQMhDUB4HD3MBEZr4kYTCv2JPQgDsdkMBnMKM+nqWdszY5DXcPkOe0sritmWrGHzUf68PlD7GobiNIfDIybi3Q6/BrhxDgPQv+eGBlhsVXUBuXjeBBvHOnl9BmlcUWoX7n0VG59aA3fDwAAHBlJREFU17wkZx0/lIE4ibHZBGfPqYjrtZRfVse3Qjfy2EXPwkXfgq59cP8H4e6VsOE3EIh2rw2voaEsPyoFMV2+9b6FfDyBOGzcuRmTqKEfdAyMjhkIqwYRicCbD/A/XZ/gGt991HWt53HXVyla/1/mmGv1dMXpEzRkRgy5pXfETMVcObOMG98xk0A4wlPb25hX7Y36LA3DaWQwwdhE0dw7QmvfCLV6Dco004PQJpQ3LfHjg3pVc7uewZVKgzBeV0qtlsEfCvPpP27k63/bxju+9zw/WLvLDO0kYu32NmqLPSzWC/niPocSD8GwjLvGgS6fmZEWizHpxd7lG9ew1rHMqihgOBCO6rmVKnwFyT2Upp7hhDcsM8oLCOjtVkDzIGaU5yOEYNn0EjY39bK1SettlKjuZawWIh0Dof3fNcTckEyPEcvb+v3ku+xxBjZViCkSkRzqHja9UysXnFJlFsRmEmUg3obMrfZSWehm4axGrfr6C1vhA7/Raiv+/iX40QJ49ttmk0FjIpxoeMngsiXTOGt2edx2w4Mw0iuL8hy4HDbNg4itom56HX5zETzyaXyuSj5u+y53LvgLj4tzsa3/Efz8LNj3HFefXs+Pr1tq5rWni3Vi33Cwh3yXnYW1Rcyp8por9cUW+xmZTHMshqPC68LtsNHUM0xb/6j53sr1dFCrB5Hv0oytkbLaEdPMLRnG32N/p4+frdvP/s4hvvHeBZwzp4KfvbCf9/3PSwkzXIb8IV7c28W7F9UkbdBojNeqQ0gp9S6uSSbwJKmoXT4/xXnOqFRxIw31gCXMlCp8BYk9CJ8/RJcvkDAE3BgzOR/qHqJRT4Vd1lBKU8+IuVLi0ob4+h3Dm0xHqG6KqYEwMMRyQwtpHxylpsgT97mXe930DgcS9rLq9GlpvLHGJ5soA/E2ZFpxHhu+epG5jjN2Jyy+Gj61Dj72FMw4G176Edy1GP56E6dKLZMnWQhgshhhJ+PuXQgtZbJzYCzEVC274aFPwG8uhv4WuPIe/nfp73hhZBYt/jzuKrgVbvw72Jzwp/dT+tTnuGJO4vblqSjOc1LodtDSN8Lrh3pZPr3UHN/Hzm4E4JTq6AnSmKjnWQyHkeq6uamPUESaE67dJqgudHO0fxQpJVub+7hofjV2mzCX/hyrok7tQTRW5GMT2gJCP3thH1csreXj58zk5zeczvc/sISj/aNmIaSVF3Z3EghFkoaXANOwWidko24iNsXVoKZYG2+sB6FVUUcXaRpeiFWH2N/pSxq+AqgpyqNLnywNmhKkuBrMMGshhglHJE09I8yo0I4zOg4/uLGZedVes9GjleoiD067SCvVtbl3BI/TFvc+x8Ry/W87kDg7rbzAhZRjSwNbMRI4TqQOqgyEYgwhYMZZWlX2LW/AGZ+AXX+n+s/v5h8VP+AjRZsgOLFOmakwPIh6SxZKld4dtLevly87H6bw12fCrsfh3H+Df90ES6+nzKv1XDrcPaxlMDWeA59dD+fdBjsehZ+eoXXETaKpJKOuNI8dRwfY1TYQlTVy/rxKfnL9Mj5wenQviZkVBTSU5fGOOeVx1zFSEGstbU6q9VTX1v5RunwBVjSWMsPS68qYYMfzINwOOzPKC3hyWxsFbgdff+8Cc5/hqb1xpDfuvLXb2ygvcEW9t7jPIEGx3L6Yzq+xVKUIMcWuY1Kri8pWA3GgcyhpeAnGwnPW6xuTZ6IQU02RB5fdxuHuIS2TKBwxPYhFdcU47VpyRLK2KnabZuTTyWQyMpgSeWTTy/JNDaJtYDROf4DUxXJNykAocpayWXDp/4MvbodLvssMexcNz90M/z0PHv+S1qr8GFc2MzUIiwtdVeBkUddTfHLLB7nZ/jDilEvh5g1w4de0EBhjX6oDnT6zSA6HGy74D/jMeqheBI/dAr+7DDp3pz2e+tI8NhzqQUo4Y+bY5CGE4PLTain0RN9tuhw2/vnvF3LF0rq46xirk1n7/kzTY+lb9WKtJfUlzKoc6+nUOai1Zs9zja/zGOG+r75nftQkXFeipQu/EbM2tj8U5vldHVy8oDpl7UtRnoMClz0qxGT07Vo4LT7LCDQNJt9lp60/Wrfo8gXikgxsNsHM8gIOWFrIH+j0JayvMDD6F1lDWEb4KJEHYbcJGsryONw9bIZ4DEPicdrNzLpUvYwayvLNFhqpaOodTpoQ0VhRwJGeYSIRSfuA3wzFWTE6unYn6MdkpoCnkY6eKZSBUKQmrwTe8a9w65vw4b/B3Etgy33wqwvhZ2fB+p/AYPukLu0wRWr9S960ga+138pXRu6kR5TylZIfwDW/hZLpUeeV69XUQ4Fw/Gp4lfPgxsfh8p9Cxw6tOPD5O9LyfOpK8pASnPbU1eHjYY1HWw1Etd5u483mfpx2wfxphcyu0rJ6QuEI7Xq3z3S49owGPnZ2I1fHeDVCCJZPL4mqGAZ4eX83Pn8oZXjJOH9aSV6UB7GttZ/KQnfSTrdCiIRLjxqN+mLRMpn0TrhDAQZGQ0n1DbBWU0d7EIUeR8IQEWiproe6h8yCuUZLOw7DMKRqzFif5sJBmgeReAKfXpZPIBRhd7u2jnmiz8/oTpzYgxihpsgzqcSQ44Xq5qpID5sdZl+g/Yz2w7a/aobima/Ds9+CuRfD0g/BvNVaK/NUhPzQc5B3BF/hHfZ9zFr/GPTsgZZNlLoq+D+Bz/Cm9900lia+Yy2LWt8iwQQhBCz/sDaWp78KL34ftj0M7/2R1q8qCcbEvqiuOK27+GQYd3yFbkdUO+1pxR6GAmFe3t/FqTVFuB12Zld6CYYlTb0jdAz6E4YhEnHxgmouTtIVdfn0UtZub48K8Tz1VhuFbkdcOCwRtSV5UZPxjtaBsVTpJFTFVFOPBsP4LG02rMysLOC5Xe2EwhHTk0jlQdTEZIAB7G4fZFalN6nYPr08n1cOdHOoawiXwxZ1937DmdMpznMm1VRA+1/oHgow5A9RkEQbGRgN0j8STFpzY3gtr+tFl4k9CO3z6R6Kzzxr6hmOq6/INspAKCaOpxhWfEz76dyjGYo3H4A9T0FeGSz5oGYsvNXQvRe69kL3Pu131x7oOwwywlcAnMDBGqiYC+f/J0+6ruDhNfuxdY9wxqzKhC9vTZsszk9hjLyV8P5fwmnXaWGxP1wOp7wHLvw6VC+IO9wIda1MEaNPB+OOsjYmNGBM/lub+/mQvh6FmZHU4aNjcJTTj0MLZyO3f8uRPi5aUE0oHOHpHW1cOL8qreaTdSUedujLWo4Gw+zt8HHR/MTGyKCmyGN2HQUSpynrzKwoIBiWtPaNmimus1NoEIVuLexlGK3RYJgtTX18RF9hLxGN5Vo67cbDvcwoy4/uZ1VVyBcvjk8dtWKErg52DZlre8RitolJZiDKNANkpE0nSj4o1T3gRCGmpt7hhNl/2SSjBkIIsRr4MWAHfi2l/F7MfjfwB+B0oBu4Vkp5SAjRCOwEjADyq1LKz2RyrIpJUjkPLv62NukeWAeb/wQb74XX7ok+zuGB8jlQuxQWXwMVc/nGej87A1X85dZ3m4eV6pXJEZl8HW5rWCmhBxHL7Avhc6/AK3fD+h/Dz98Bp12vaRaW8NUpNf+/vXsPjuuuDjj+PbsraaWVrMdKsmVbluRYeWA7wY7sQCDGgaQE0hnT4ZEAnUkKNOCGBKbDaygUJlNKmwHKQNKHMwkNlMcACSGdQiAQICE4jp9JbDMBR7Yjv2RLsmzLsiXt7ukfv7vSSrq7K1laraw9n5mdvbqrx++nK92zv9f5ufTkb7rMPzBN1KLhADH6HWPq1NurvPToyRvjvhN9dJ7OvKPdRK1cVEkoIOx41W3Os2V/Dyf7h3hbmtXTYzVUltLVN8j5oTgvHztDPKFZWxDzK8McP+1SpIjI8BqI2orxAXzp8FTXPtq9d/iZsgqLyKi1ELs6ehmMJYZTTvhJvnt/oaOXN1+eObj5SV6fnR29aQPEdi8gXrnY//WFVWFCARluQfi1DkPBAFVlReO6mAZicY6dPj/pjADTLWcBQkSCwP3AjcAhYKuIPK6qe1M+7YPASVVdJiK3Av8K3OK99oqq+u8zaGafYMh1M7XeCP09bjZRbMC1DGpbYd5iGJPR9d01pxgaM9ModSpgugBREgpSURLizECM6sgEp7QWlcK6T0DbB+CZr8LzD8DuH8OaD8F1n4BIlEvqytn2uRtHdWFdiPoKN4tmbAsitYthpXdTqSwrorbcDSoPxhITHoPIJFwU5DUL5w3vffDz3UcpLQrypkvrs3ylkyz3sVPnhweo090kkxbMCzMYT3Cyf4iaSLHvKuqk5pSpru0n+miJRrImjWyoLB0epN7S3oNI5pZekzfmkNCRdRGT0VjjBvu3H+gZ3gt8rC37u1lUVZp2llEo6AJfcqA83QJIv8VyLi+Y/yD8TMplC2ItsE9V2wFE5AfABiA1QGwAvugd/xi4T9J1KpqLR1mN637KYqXPO6/UoJDpZllT7vamTu6xPamyvfVL8LqN8Nsvu5bOju/AG+6G1/0dNZELWwyYKhgQvvm+VVy+YHQ3RvIGES4KDGeFBVhWH+E5L69OxhZE33G35ew4Y/5lRLi5tpMn93YydKSc3+0+yPWXN0x4XCXZ8jnSe47dR04xLxzKmrokdWe5mkjxcB4mvyAfjRRTEQ55AeLsyHqcDBZUhnl2XxfgbsyXL5jnuwdJ0qKq0uENqZoyjDWkIyK0NVWz3We6MLjZV8/v7+G61sytzaZohIPd/VSXFaXt3otGiseNQcyGNRCQ2wCxCEj9az4EXJPuc1Q1JiKngGS7sUVEdgKngc+p6jNjf4CI3AHcAbBkyZKxL5uLUOo7znQtCGB4Q5ZMN4mMKhfDhvvh9Xe5rVp/8yV4fhOs+xRcfXv2gfYs/GYLhYuC1ESKWVobGZWb6pK6kQ1g5ifrHI/B8T1uBXnH83DoeTh5YMI//8PAhwPAJngGON9RBw+1uunLNS3es3ccHh2ok+lKDveeY8+R0yxfWJl2MDgpNd3GaxbOG0mzERl/DUWEpbUR/tR5hld7+nnbyuxdXw2VYY6fGeD8UJwdr57k1jWZ/9+LQwEWVZXyak//BbUgwM1y+vnuY94it9GB+5UTfXT1DXJNlnQXTd4NPtPkg5pI8bgEhsk0H3O5BTEVR4ElqtotIlcDj4nIclUdtXu5qm4CNgG0tbVNbVK+mRWKgoHhJrffAGdScv74hMYgMqm/3C0M7NjqZmP9/JPw3P1w/edgxTvHdYtN1R3rlg7fNJIuqSunkj5WBf7MZXu3wNM74PAOGPJuGuULoHGt6w6LLgNJKdO4tSjeZktnBvjMoy9SXxKnLnaUu1oDcOoA7PsV9B0b/SVl0ZGAUd3MotI6bgocInHgDANHz3Jd23L3czIEieRMo/1dZ7ne+/mVpUVpN9xqqY3wfy8dJZbQjIvkUr9/PKH86o+dnB9K8Lql2ScSNEXLvABxYRkAktNgtx08ydtXNox6bYs3rpBpHCRZBsgcIKLlJWw7MLqlcqinn+JQYFq6HKcilwHiMJC6mcJi75zf5xwSkRBQCXSrS/U4AKCq20XkFeBSYFsOy2tmifqKEhcgMvxzJFN8V2WaxTQZjWvc+ol9v3aB4tEPuXQjS65xN+iK+SnP8yFS78ZdJmroHJzt4iOtZ6B/P7zwNPR3QedebmnfzAfCLp2Jbg/CgpWw6q9dUGhcC5WNGW/OfmpVeeEJt3/1DVfUU/TONSMvDvS51khP+8jj5H44+Ad48YcUofxnMbAbbgkBu4AXQ1BWC5E6iCSf6yAShaIIDcES7q7t4OWnttFXsZra40e4vjThAl0o7BYyhsJuLCgQorU6iMQHCRJgaW32d8nJtRCP7TwCwNqW7LN7WmojbNnfM/y1k7V8YSUloQDbDvgEiPYe6itKsrZOki0AvymuSdFIMSf7B0kkdHi21as9bgHe2CyuMy2XAWIr0CoiLbhAcCvwvjGf8zhwG7AZeBfwlKqqiNQBPaoaF5GlQCvQnsOymlmkrqKEw73nMi4Qqp9XQiggzAtP45+wCLTe4GY97XkUNt8Hex6Dc377/4q7UaYGj/I6iA1Cf7e7+Z/tcgP2/V0wlGZVbmkNgYY27u1uY2/oCv77s3dA8dRzXiUzlz65t5ObVoy+uVFSDgtWuMdY8SHo7+buB39Jz/Ej1HCaz6+voy5wGs6e8OrU5QLK2S4YdNNUA8DfJ7/HT+BjyeMH/Mt3J3Bn8p75LVyrKBACCbrngPdxIAQS4Lp4gs0lQ9AO/1waoGZTKSDe8It4AdR7DhZDcYR/CJTy8eYwoccecb/T4nLvEXGPkgr37AWtsT+/WIL85YJeOtt7obtkuIwqAf7U3s76pjpksM/lAQsWubVCYyQHy9Pm11IlWioU6wCnerupLhFIxOjq7qKxanwiwZmWswDhjSl8FPgFbprrQ6q6R0TuAbap6uPAg8B3RGQf0IMLIgDrgHtEZAhIAB9R1ZnZpdvk3VWLq7Jm8bjt2mauaYmm3SFuSgIBl7xw5bvcx7EBN0Dc1wlnjrnn1OMzx6BzrzsOhd276rKoe4ddf4U7Lou6gFIWde/Ey6Lu88JVlCh86wu/oKEiPC3BIWlday3PvdLNDVdMbPYS4G50FQsYjC7n98eihIsC/NsNN7nNQPwMnXfBLzYAsXN8+5mX+eFz+6gIxri2qZy71jVC7PzIY+g8JGIc6+3j28+2U1ECG69rgUQMNO6eEwnv2XugJIbiPL3zMIKyLBqhvrEKUK+LTVO62tTtnDjYT8lgHyVDnXC43bWaBs+OdNtN0FeTB98cOSfAEwD7gC+nfra44BIs8oJGiEsDIbaWJZi3MwAvJFwATtYrPgQa53bg9jDwjZHv9CMg1huCr0RH/n5Kq73jmpRz3nF5PVRN/+6XOR2DUNWfAT8bc+4fU47PA+/2+bpHgEdyWTYze33irZdl/Zz6inDWpHbTJlTi/vmy/QNm6adPJyBuw6F5Ux1PGeP91zSxYdWiUau5Jyo51fWKhnmZp6AWhd3Dc+vNzXxvf4TNx85w2fxmuGy575eVD8T496d/wdr6GjZe//qs5SlW5fM7n2AwluC+9atYfeXCSdVnWCLhgsSg9xg44wJcIj4+QGmclzq62fTbP3P3m5fSWlsKiTjb2jv56c4O7l7fTF1ZEBJDblJBIuYdjwQBiQ9Rl4i51kewyGuduOCRPD7QO8j3tx3lfa9voamuinMx+NrPdvH2ZSWsisa9VmiPyyvW3w3nTrqyplq4Gu74zYX9TjKYrYPUxlx8pjBD++u3riI4zTO8AwG5oOAAI1NdVyzMvP5hrOJQgK+8+yrecf+zGXcfLC8J0VIbybq+IklEaKgMc7C7f2ob5QQCrmupJPvUWoDGpkH+96knuTx4Ga2vXQbA9/bt4nfhE9xzww1TuuZJ/UdO819bnuGqptU0rWzglcOneCC+mKvXrIax3YPgAtjAqZHA0d895Vl36ViAMGYWSLdbW74kWxDZVlD7WbGokqc/db3vIrlUj268dlI5rxZXlxIKyMy1HHGTIJbVlw+vmgY3QL22pSbr1N+JSu4lkdybOt0mRMMCAdfdVFoN0UumpQzpWIAwxoxzdVM1a5qrh3fTm6yxq8j9VE9yxfo9G1YQi8/8bPY2bz3Ero5eNr/SzeHec/ztdeO30L1Qyd9Dj7e4MLlIbrLb5uaCBQhjzDjz54X50UeuzXcxRrnQLW+nanVTNT/Y2sE77n8WcK29t2RJXjgZRcEAjTWl/M+Wg6y7tJaOk/1UlhZdcPfgdLIAYYwxGdy8soHOU+dZWldOW3P1hFOyT8aDt63hQw9v45ZNzxGNFOd9BXWSbRhkjDEZREpC3PWWVm6+siEnwQHg0vkVPHbnG1jVWMXRU+fzvg9EkrUgjDFmFqiJFPOdD17Dg7/fz9qWqe8LMh0sQBhjzCxRHAqwcX1uZyZNhnUxGWOM8WUBwhhjjC8LEMYYY3xZgDDGGOPLAoQxxhhfFiCMMcb4sgBhjDHGlwUIY4wxvkSzbd11kRCRE8DBKXyLWqBrmopzsSi0OhdafcHqXCimUucmVfVN2ztnAsRUicg2VW3LdzlmUqHVudDqC1bnQpGrOlsXkzHGGF8WIIwxxviyADFiU74LkAeFVudCqy9YnQtFTupsYxDGGGN8WQvCGGOMLwsQxhhjfBV8gBCRm0TkZRHZJyKfyXd5ZoKIHBCRl0Rkl4hsy3d5ckFEHhKR4yKyO+VcjYg8KSJ/9p5nx7Zd0yRNnb8oIoe9a71LRN6ezzJONxFpFJHfiMheEdkjIh/zzs/Ja52hvjm5zgU9BiEiQeBPwI3AIWAr8F5V3ZvXguWYiBwA2lR1zi4mEpF1QB/wbVVd4Z27F+hR1X/x3gxUq+qn81nO6ZSmzl8E+lT1K/ksW66ISAPQoKo7RKQC2A68A7idOXitM9T3PeTgOhd6C2ItsE9V21V1EPgBsCHPZTLTQFWfBnrGnN4APOwdP4z7x5oz0tR5TlPVo6q6wzs+A/wRWMQcvdYZ6psThR4gFgEdKR8fIoe/7FlEgV+KyHYRuSPfhZlB81X1qHd8DJifz8LMoI+KyIteF9Sc6GrxIyLNwCpgCwVwrcfUF3JwnQs9QBSqN6rqauBtwJ1e10RBUde3Wgj9q/8BXAK8FjgKfDW/xckNESkHHgE+rqqnU1+bi9fap745uc6FHiAOA40pHy/2zs1pqnrYez4O/ATX1VYIOr0+3GRf7vE8lyfnVLVTVeOqmgAeYA5eaxEpwt0sv6uqj3qn5+y19qtvrq5zoQeIrUCriLSISDFwK/B4nsuUUyIS8Qa3EJEI8BfA7sxfNWc8DtzmHd8G/DSPZZkRyZuk56+YY9daRAR4EPijqn4t5aU5ea3T1TdX17mgZzEBeNPBvg4EgYdU9Ut5LlJOichSXKsBIAR8by7WWUS+D6zHpUHuBL4APAb8EFiCSw3/HlWdM4O6aeq8HtftoMAB4MMpffMXPRF5I/AM8BKQ8E5/FtcvP+eudYb6vpccXOeCDxDGGGP8FXoXkzHGmDQsQBhjjPFlAcIYY4wvCxDGGGN8WYAwxhjjywKEMZMgIvGUjJm7pjMDsIg0p2ZiNSbfQvkugDEXmXOq+tp8F8KYmWAtCGOmgbfHxr3ePhvPi8gy73yziDzlJVH7tYgs8c7PF5GfiMgL3uNa71sFReQBL9f/L0WkNG+VMgXPAoQxk1M6povplpTXTqnqSuA+3Op8gG8CD6vqlcB3gW94578B/E5VrwJWA3u8863A/aq6HOgF3pnj+hiTlq2kNmYSRKRPVct9zh8A3qyq7V4ytWOqGhWRLtwGL0Pe+aOqWisiJ4DFqjqQ8j2agSdVtdX7+NNAkar+U+5rZsx41oIwZvpomuPJGEg5jmPjhCaPLEAYM31uSXne7B3/AZclGOD9uERrAL8GNoLb+lZEKmeqkMZMlL07MWZySkVkV8rHT6hqcqprtYi8iGsFvNc7dxfwLRH5JHAC+Bvv/MeATSLyQVxLYSNuoxdjZg0bgzBmGnhjEG2q2pXvshgzXayLyRhjjC9rQRhjjPFlLQhjjDG+LEAYY4zxZQHCGGOMLwsQxhhjfFmAMMYY4+v/AfR2uWwLr8vYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "NUM_EPOCHS = 25\n",
    "train_its = int(np.ceil(training_kp.size(0)/batch_size))\n",
    "timer_beg = timer()\n",
    "tr_losses = [], [] # x_axis, y_axis\n",
    "val_losses = [], []\n",
    "\n",
    "model.train()\n",
    "for i in range(NUM_EPOCHS):\n",
    "    # Init the hidden state (ht, ct)\n",
    "    h = model.init_hidden(batch_size)\n",
    "    counter = i\n",
    "    for inputs, labels in train_loader:\n",
    "        h = tuple([e.data for e in h])\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward step\n",
    "        output, h = model(inputs, h)\n",
    "        # Loss calculation and backward step\n",
    "        loss = loss_function(output, labels.float())\n",
    "        loss.backward()\n",
    "        # Weight update\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Output data collection for showing\n",
    "        tr_losses[0].append(counter)\n",
    "        tr_losses[1].append(loss.item())\n",
    "        writer.add_scalar('Loss/train', tr_losses[1][-1], counter)   \n",
    "        counter += 1/train_its\n",
    "    timer_end = timer()\n",
    "    \n",
    "    # Validation at the end of an epoch\n",
    "    val_h = model.init_hidden(batch_size)\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    for inp, lab in val_loader:\n",
    "        val_h = tuple([each.data for each in val_h])\n",
    "        inp, lab = inp.to(device), lab.to(device)\n",
    "        out, val_h = model(inp, val_h)\n",
    "        val_loss.append(loss_function(out, lab.float()).item())\n",
    "    val_losses[0].append(i+1)\n",
    "    val_losses[1].append(np.mean(val_loss))\n",
    "    writer.add_scalar('Loss/validation', val_losses[1][-1], i+1)  \n",
    "    model.train()\n",
    "    \n",
    "    # Output loss and training time.\n",
    "    print(f\"Finished epoch {i+1}/{NUM_EPOCHS} in {(timer_end-timer_beg):.2f}s.\\n\",\n",
    "             f\"Loss: {np.mean(tr_losses[1][-train_its:]):.4f}\",\n",
    "             f\" Val Loss: {val_losses[1][-1]}\")\n",
    "    timer_beg = timer()\n",
    "\n",
    "plt.plot(tr_losses[0], tr_losses[1], label='train')\n",
    "plt.plot(val_losses[0], val_losses[1], label='validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSELoss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './state_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./state_dict.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "After the training, we shall proceed with the performance test. This will go through the test batches and perform the inference, then it will show the test loss, as well as the performance metric. In this case, as we are working with human body keypoints, we will use the Mean Per Joint Position Error (MPJPE) metric, which outputs the mean euclidean distance between the joints (keypoints) positions estimated and the ones in the groundtruth.\n",
    "\n",
    "The formula for MPJPE is the following:\n",
    "\n",
    "$\\text{MPJPE} = \\frac1T\\frac1N\\displaystyle\\sum_{t=1}^{T}\\displaystyle\\sum_{i=1}^{N}\\|(J_{i}^{(t)}-J_{root}^{(t)})-(Ĵ_{i}^{(t)}-Ĵ_{root}^{(t)})\\|$\n",
    "\n",
    "Where N is the number of joints, and T the number of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen in the formula above, we need to align the root joints of the labels and the network output. In order to do that, I have defined a function that substracts the root joint of each keypoint set (face, hands, body) in the corresponding keypoint set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substract_root_PJPE(output):\n",
    "    jf = torch.chunk(output[:, :, :70], max_seq, dim=1)\n",
    "    jhl, jhr = torch.chunk(output[:, :, 70:91], max_seq, dim=1), torch.chunk(output[:, :, 91:112], max_seq, dim=1)\n",
    "    jb = torch.chunk(output[:, :, 112:], max_seq, dim=1)\n",
    "    joints_merged = []\n",
    "    roots = [33, 0, 0, 8]\n",
    "    for i, joints in enumerate((jf, jhl, jhr, jb)):\n",
    "        n_joints = []\n",
    "        for chunk in joints:\n",
    "            n_joints.append(chunk.sub(chunk[:,:,roots[i]]))\n",
    "        joints_merged.append(torch.cat(tuple(n_joints), dim=1))\n",
    "    joints_merged = torch.cat(tuple(joints_merged), dim=2)\n",
    "    return joints_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_losses = []\n",
    "MPJPE = []\n",
    "h = model.init_hidden(batch_size)\n",
    "\n",
    "model.eval()\n",
    "for inputs, labels in test_loader:\n",
    "    h = tuple([each.data for each in h])\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    output, h = model(inputs, h)\n",
    "    test_loss = loss_function(output, labels.float())\n",
    "    test_losses.append(test_loss.item())\n",
    "    rooted_o, rooted_l = substract_root_PJPE(output), substract_root_PJPE(labels)\n",
    "    MPJPE.append(rooted_o.sub(rooted_l).abs().mean().item())\n",
    "MPJPE_total = np.mean(MPJPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 66.0165 \n",
      "Test loss: 0.0822\n"
     ]
    }
   ],
   "source": [
    "print(f\"MPJPE: {MPJPE_total*scale[0]:.4f}\", f\"\\nTest loss: {np.mean(test_losses):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
