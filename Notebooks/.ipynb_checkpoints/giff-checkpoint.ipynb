{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch utilities\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Plotting utilities\n",
    "%matplotlib widget\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from IPython.display import HTML\n",
    "import matplotlib.animation as animation\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from timeit import default_timer as timer\n",
    "import pyprind\n",
    "\n",
    "# Directory and file utilities\n",
    "from os import listdir\n",
    "from os.path import isfile, isdir, join\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../results/small_body_S.json', 'r') as j:\n",
    "    jd = json.load(j)\n",
    "    tr, val, test = jd['train'], jd['validation'], jd['test']\n",
    "    tr_inputs, tr_predictions, tr_groundtruth, tr_lengths = tuple(torch.tensor(tr[n]) for n in ['inputs', 'predictions',\n",
    "                                                                                              'labels', 'lengths'])\n",
    "    val_inputs, val_predictions, val_groundtruth, val_length = tuple(torch.tensor(val[n]) for n in ['inputs', 'predictions',\n",
    "                                                                                              'labels', 'lengths'])\n",
    "    test_inputs, test_predictions, test_groundtruth, test_lengths = tuple(torch.tensor(test[n]) for n in ['inputs', 'predictions',\n",
    "                                                                                              'labels', 'lengths'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([288, 250, 52]), torch.Size([32, 250, 26]), torch.Size([38]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_inputs.shape, val_predictions.shape, test_lengths.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [i for i in range(1,9,2)]\n",
    "video_n = 34\n",
    "\n",
    "c_inputs = tr_inputs.clone()\n",
    "c_output = tr_predictions.clone()\n",
    "c_labels = tr_groundtruth.clone()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vid in range(c_labels.shape[0]): \n",
    "    c_inputs[vid,:,::2].mul_(tr_inp_scale[vid, 0])\n",
    "    c_inputs[vid,:,1::2].mul_(tr_inp_scale[vid, 1])\n",
    "    c_output[vid].mul_(tr_out_scale[vid])\n",
    "    c_labels[vid].mul_(tr_out_scale[vid])\n",
    "    \n",
    "    c_inputs[vid,:,::2].mul_(tr_mx[vid, 1])\n",
    "    c_inputs[vid,:,1::2].mul_(tr_my[vid, 1])\n",
    "    c_output[vid].mul_(tr_mz[vid])\n",
    "    c_labels[vid].mul_(tr_mz[vid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_tight_layout(True)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "# Query the figure's on-screen size and DPI. Note that when saving the figure to\n",
    "# a file, we need to provide a DPI for that separately.\n",
    "print('fig size: {0} DPI, size in inches {1}'.format(\n",
    "    fig.get_dpi(), fig.get_size_inches()))\n",
    "\n",
    "frames = [i for i in range(1,60)]\n",
    "inp = c_inputs\n",
    "preds = c_output\n",
    "bodiesXY = torch.chunk(inp[video_n, frames, :], len(frames), dim=0)\n",
    "pred_bodiesZ = torch.chunk(preds[video_n, frames, :], len(frames), dim=0)\n",
    "def update(j, train=True):\n",
    "    \n",
    "    label = 'timestep {0}'.format(j)\n",
    "    # Update the line and the axes (with a new xlabel). Return a tuple of\n",
    "    # \"artists\" that have to be redrawn for this frame.\n",
    "    \n",
    "    x = bodiesXY[j].squeeze()[::2].tolist()\n",
    "    y = bodiesXY[j].squeeze()[1::2].tolist()\n",
    "    pred_z = pred_bodiesZ[j].squeeze().tolist()\n",
    "    if not train:\n",
    "        print((x2.max()-x2.min())/(x1.max()-x1.min()))\n",
    "        x1 = x1*((x2.max()-x2.min())/(x1.max()-x1.min()))\n",
    "\n",
    "    r = R.from_euler('y', -60, degrees=True)\n",
    "\n",
    "    xyz1 = np.asarray([c for c in zip(x, y, pred_z)])\n",
    "    xyz1 = r.apply(xyz1)\n",
    "    x1 = xyz1[:,0]\n",
    "    y1 = xyz1[:,1]\n",
    "    pred_z = xyz1[:,2]\n",
    "\n",
    "    r_arm = [[c[i] for i in [1, 0, 9, 10, 11]] for c in [x1, y1, pred_z]]\n",
    "    l_arm = [[c[i] for i in [0, 3, 4, 5]] for c in [x1, y1, pred_z]]\n",
    "    r_leg = [[c[i] for i in [0, 2, 12, 13, 14, 22, 23, 24]] for c in [x1, y1, pred_z]]\n",
    "    l_leg = [[c[i] for i in [2, 6, 7, 8, 19, 20, 21]] for c in [x1, y1, pred_z]]\n",
    "    head = [[c[i] for i in [18, 17, 1, 15, 16]] for c in [x1, y1, pred_z]]\n",
    "\n",
    "    ax.plot(r_arm[0], r_arm[1], r_arm[2])\n",
    "    ax.plot(l_arm[0], l_arm[1], l_arm[2])\n",
    "    ax.plot(r_leg[0], r_leg[1], r_leg[2])\n",
    "    ax.plot(l_leg[0], l_leg[1], l_leg[2])\n",
    "    ax.plot(head[0], head[1], head[2])\n",
    "\n",
    "    lims = ax.get_xlim(), ax.get_ylim(), ax.get_zlim()\n",
    "    spans = lims[0][1]-lims[0][0], lims[1][1]-lims[1][0], lims[2][1]-lims[2][0]\n",
    "    span = max(spans)\n",
    "    margins = [(span-s)/2 for  s in spans]\n",
    "    ax.set_xlim(lims[0][0]-margins[0], lims[0][1]+margins[0])\n",
    "    ax.set_ylim(lims[1][0]-margins[1], lims[1][1]+margins[1])\n",
    "    ax.set_zlim(lims[2][0]-margins[2], lims[2][1]+margins[2])\n",
    "\n",
    "    ax.view_init(elev=-65., azim=-90.)\n",
    "    \n",
    "    ax.set_xlabel(label)\n",
    "    \n",
    "    return line, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FuncAnimation will call the 'update' function for each frame; here\n",
    "# animating over 10 frames, with an interval of 200ms between frames.\n",
    "anim = FuncAnimation(fig, update, frames=np.arange(0, 60), interval=100)\n",
    "if len(sys.argv) > 1 and sys.argv[1] == 'save':\n",
    "    anim.save('body.gif', dpi=80, writer='imagemagick')\n",
    "else:\n",
    "    # plt.show() will just loop the animation forever.\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
